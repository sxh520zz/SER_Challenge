nohup: 忽略输入
Some weights of the model checkpoint at /mnt/data1/liyongwei/SSL_Models/facebook/hubert-large-ls960-ft were not used when initializing HubertModel: ['lm_head.weight', 'lm_head.bias']
- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 1 [320/53386 (1%)]	Loss: 2.403577
Train Epoch: 1 [640/53386 (1%)]	Loss: 2.082497
Train Epoch: 1 [960/53386 (2%)]	Loss: 1.944153
Train Epoch: 1 [1280/53386 (2%)]	Loss: 1.863059
Train Epoch: 1 [1600/53386 (3%)]	Loss: 1.800685
Train Epoch: 1 [1920/53386 (4%)]	Loss: 1.697976
Train Epoch: 1 [2240/53386 (4%)]	Loss: 1.704895
Train Epoch: 1 [2560/53386 (5%)]	Loss: 1.606268
Train Epoch: 1 [2880/53386 (5%)]	Loss: 1.731902
Train Epoch: 1 [3200/53386 (6%)]	Loss: 1.674072
Train Epoch: 1 [3520/53386 (7%)]	Loss: 1.596844
Train Epoch: 1 [3840/53386 (7%)]	Loss: 1.662500
Train Epoch: 1 [4160/53386 (8%)]	Loss: 1.565408
Train Epoch: 1 [4480/53386 (8%)]	Loss: 1.639636
Train Epoch: 1 [4800/53386 (9%)]	Loss: 1.563866
Train Epoch: 1 [5120/53386 (10%)]	Loss: 1.658882
Train Epoch: 1 [5440/53386 (10%)]	Loss: 1.579707
Train Epoch: 1 [5760/53386 (11%)]	Loss: 1.579899
Train Epoch: 1 [6080/53386 (11%)]	Loss: 1.602373
Train Epoch: 1 [6400/53386 (12%)]	Loss: 1.494669
Train Epoch: 1 [6720/53386 (13%)]	Loss: 1.595309
Train Epoch: 1 [7040/53386 (13%)]	Loss: 1.525390
Train Epoch: 1 [7360/53386 (14%)]	Loss: 1.519134
Train Epoch: 1 [7680/53386 (14%)]	Loss: 1.567351
Train Epoch: 1 [8000/53386 (15%)]	Loss: 1.555026
Train Epoch: 1 [8320/53386 (16%)]	Loss: 1.529857
Train Epoch: 1 [8640/53386 (16%)]	Loss: 1.428295
Train Epoch: 1 [8960/53386 (17%)]	Loss: 1.565090
Train Epoch: 1 [9280/53386 (17%)]	Loss: 1.516607
Train Epoch: 1 [9600/53386 (18%)]	Loss: 1.520136
Train Epoch: 1 [9920/53386 (19%)]	Loss: 1.532671
Train Epoch: 1 [10240/53386 (19%)]	Loss: 1.517083
Train Epoch: 1 [10560/53386 (20%)]	Loss: 1.541903
Train Epoch: 1 [10880/53386 (20%)]	Loss: 1.466400
Train Epoch: 1 [11200/53386 (21%)]	Loss: 1.530660
Train Epoch: 1 [11520/53386 (22%)]	Loss: 1.464054
Train Epoch: 1 [11840/53386 (22%)]	Loss: 1.527824
Train Epoch: 1 [12160/53386 (23%)]	Loss: 1.624341
Train Epoch: 1 [12480/53386 (23%)]	Loss: 1.511052
Train Epoch: 1 [12800/53386 (24%)]	Loss: 1.467524
Train Epoch: 1 [13120/53386 (25%)]	Loss: 1.525478
Train Epoch: 1 [13440/53386 (25%)]	Loss: 1.502138
Train Epoch: 1 [13760/53386 (26%)]	Loss: 1.578415
Train Epoch: 1 [14080/53386 (26%)]	Loss: 1.598251
Train Epoch: 1 [14400/53386 (27%)]	Loss: 1.631883
Train Epoch: 1 [14720/53386 (28%)]	Loss: 1.501456
Train Epoch: 1 [15040/53386 (28%)]	Loss: 1.561008
Train Epoch: 1 [15360/53386 (29%)]	Loss: 1.577881
Train Epoch: 1 [15680/53386 (29%)]	Loss: 1.568785
Train Epoch: 1 [16000/53386 (30%)]	Loss: 1.600889
Train Epoch: 1 [16320/53386 (31%)]	Loss: 1.527372
Train Epoch: 1 [16640/53386 (31%)]	Loss: 1.425747
Train Epoch: 1 [16960/53386 (32%)]	Loss: 1.440337
Train Epoch: 1 [17280/53386 (32%)]	Loss: 1.580976
Train Epoch: 1 [17600/53386 (33%)]	Loss: 1.554573
Train Epoch: 1 [17920/53386 (34%)]	Loss: 1.421541
Train Epoch: 1 [18240/53386 (34%)]	Loss: 1.502476
Train Epoch: 1 [18560/53386 (35%)]	Loss: 1.529042
Train Epoch: 1 [18880/53386 (35%)]	Loss: 1.478078
Train Epoch: 1 [19200/53386 (36%)]	Loss: 1.548143
Train Epoch: 1 [19520/53386 (37%)]	Loss: 1.507296
Train Epoch: 1 [19840/53386 (37%)]	Loss: 1.560760
Train Epoch: 1 [20160/53386 (38%)]	Loss: 1.442506
Train Epoch: 1 [20480/53386 (38%)]	Loss: 1.627520
Train Epoch: 1 [20800/53386 (39%)]	Loss: 1.523077
Train Epoch: 1 [21120/53386 (40%)]	Loss: 1.488568
Train Epoch: 1 [21440/53386 (40%)]	Loss: 1.504039
Train Epoch: 1 [21760/53386 (41%)]	Loss: 1.510198
Train Epoch: 1 [22080/53386 (41%)]	Loss: 1.516403
Train Epoch: 1 [22400/53386 (42%)]	Loss: 1.490524
Train Epoch: 1 [22720/53386 (43%)]	Loss: 1.522438
Train Epoch: 1 [23040/53386 (43%)]	Loss: 1.480105
Train Epoch: 1 [23360/53386 (44%)]	Loss: 1.541318
Train Epoch: 1 [23680/53386 (44%)]	Loss: 1.462737
Train Epoch: 1 [24000/53386 (45%)]	Loss: 1.460080
Train Epoch: 1 [24320/53386 (46%)]	Loss: 1.443776
Train Epoch: 1 [24640/53386 (46%)]	Loss: 1.512957
Train Epoch: 1 [24960/53386 (47%)]	Loss: 1.421243
Train Epoch: 1 [25280/53386 (47%)]	Loss: 1.503070
Train Epoch: 1 [25600/53386 (48%)]	Loss: 1.477948
Train Epoch: 1 [25920/53386 (49%)]	Loss: 1.486655
Train Epoch: 1 [26240/53386 (49%)]	Loss: 1.396860
Train Epoch: 1 [26560/53386 (50%)]	Loss: 1.501540
Train Epoch: 1 [26880/53386 (50%)]	Loss: 1.479724
Train Epoch: 1 [27200/53386 (51%)]	Loss: 1.563706
Train Epoch: 1 [27520/53386 (52%)]	Loss: 1.484172
Train Epoch: 1 [27840/53386 (52%)]	Loss: 1.529145
Train Epoch: 1 [28160/53386 (53%)]	Loss: 1.448155
Train Epoch: 1 [28480/53386 (53%)]	Loss: 1.426544
Train Epoch: 1 [28800/53386 (54%)]	Loss: 1.360424
Train Epoch: 1 [29120/53386 (55%)]	Loss: 1.510745
Train Epoch: 1 [29440/53386 (55%)]	Loss: 1.525103
Train Epoch: 1 [29760/53386 (56%)]	Loss: 1.409419
Train Epoch: 1 [30080/53386 (56%)]	Loss: 1.509204
Train Epoch: 1 [30400/53386 (57%)]	Loss: 1.496492
Train Epoch: 1 [30720/53386 (58%)]	Loss: 1.500699
Train Epoch: 1 [31040/53386 (58%)]	Loss: 1.430365
Train Epoch: 1 [31360/53386 (59%)]	Loss: 1.460860
Train Epoch: 1 [31680/53386 (59%)]	Loss: 1.429325
Train Epoch: 1 [32000/53386 (60%)]	Loss: 1.479459
Train Epoch: 1 [32320/53386 (61%)]	Loss: 1.537803
Train Epoch: 1 [32640/53386 (61%)]	Loss: 1.425351
Train Epoch: 1 [32960/53386 (62%)]	Loss: 1.513349
Train Epoch: 1 [33280/53386 (62%)]	Loss: 1.489671
Train Epoch: 1 [33600/53386 (63%)]	Loss: 1.443720
Train Epoch: 1 [33920/53386 (64%)]	Loss: 1.565849
Train Epoch: 1 [34240/53386 (64%)]	Loss: 1.384690
Train Epoch: 1 [34560/53386 (65%)]	Loss: 1.455672
Train Epoch: 1 [34880/53386 (65%)]	Loss: 1.447539
Train Epoch: 1 [35200/53386 (66%)]	Loss: 1.399344
Train Epoch: 1 [35520/53386 (67%)]	Loss: 1.485875
Train Epoch: 1 [35840/53386 (67%)]	Loss: 1.446974
Train Epoch: 1 [36160/53386 (68%)]	Loss: 1.453196
Train Epoch: 1 [36480/53386 (68%)]	Loss: 1.457693
Train Epoch: 1 [36800/53386 (69%)]	Loss: 1.412881
Train Epoch: 1 [37120/53386 (70%)]	Loss: 1.483526
Train Epoch: 1 [37440/53386 (70%)]	Loss: 1.563383
Train Epoch: 1 [37760/53386 (71%)]	Loss: 1.386381
Train Epoch: 1 [38080/53386 (71%)]	Loss: 1.463196
Train Epoch: 1 [38400/53386 (72%)]	Loss: 1.426370
Train Epoch: 1 [38720/53386 (73%)]	Loss: 1.438261
Train Epoch: 1 [39040/53386 (73%)]	Loss: 1.527811
Train Epoch: 1 [39360/53386 (74%)]	Loss: 1.416431
Train Epoch: 1 [39680/53386 (74%)]	Loss: 1.352073
Train Epoch: 1 [40000/53386 (75%)]	Loss: 1.368215
Train Epoch: 1 [40320/53386 (76%)]	Loss: 1.428243
Train Epoch: 1 [40640/53386 (76%)]	Loss: 1.501435
Train Epoch: 1 [40960/53386 (77%)]	Loss: 1.517878
Train Epoch: 1 [41280/53386 (77%)]	Loss: 1.449485
Train Epoch: 1 [41600/53386 (78%)]	Loss: 1.520490
Train Epoch: 1 [41920/53386 (79%)]	Loss: 1.457302
Train Epoch: 1 [42240/53386 (79%)]	Loss: 1.371201
Train Epoch: 1 [42560/53386 (80%)]	Loss: 1.476674
Train Epoch: 1 [42880/53386 (80%)]	Loss: 1.387681
Train Epoch: 1 [43200/53386 (81%)]	Loss: 1.476210
Train Epoch: 1 [43520/53386 (82%)]	Loss: 1.455918
Train Epoch: 1 [43840/53386 (82%)]	Loss: 1.511551
Train Epoch: 1 [44160/53386 (83%)]	Loss: 1.485036
Train Epoch: 1 [44480/53386 (83%)]	Loss: 1.414179
Train Epoch: 1 [44800/53386 (84%)]	Loss: 1.376188
Train Epoch: 1 [45120/53386 (85%)]	Loss: 1.422580
Train Epoch: 1 [45440/53386 (85%)]	Loss: 1.406867
Train Epoch: 1 [45760/53386 (86%)]	Loss: 1.439007
Train Epoch: 1 [46080/53386 (86%)]	Loss: 1.413277
Train Epoch: 1 [46400/53386 (87%)]	Loss: 1.419294
Train Epoch: 1 [46720/53386 (88%)]	Loss: 1.481662
Train Epoch: 1 [47040/53386 (88%)]	Loss: 1.474341
Train Epoch: 1 [47360/53386 (89%)]	Loss: 1.459668
Train Epoch: 1 [47680/53386 (89%)]	Loss: 1.460809
Train Epoch: 1 [48000/53386 (90%)]	Loss: 1.371329
Train Epoch: 1 [48320/53386 (91%)]	Loss: 1.451684
Train Epoch: 1 [48640/53386 (91%)]	Loss: 1.524811
Train Epoch: 1 [48960/53386 (92%)]	Loss: 1.469770
Train Epoch: 1 [49280/53386 (92%)]	Loss: 1.360327
Train Epoch: 1 [49600/53386 (93%)]	Loss: 1.412879
Train Epoch: 1 [49920/53386 (94%)]	Loss: 1.460236
Train Epoch: 1 [50240/53386 (94%)]	Loss: 1.383845
Train Epoch: 1 [50560/53386 (95%)]	Loss: 1.458351
Train Epoch: 1 [50880/53386 (95%)]	Loss: 1.477765
Train Epoch: 1 [51200/53386 (96%)]	Loss: 1.469925
Train Epoch: 1 [51520/53386 (97%)]	Loss: 1.404566
Train Epoch: 1 [51840/53386 (97%)]	Loss: 1.346268
Train Epoch: 1 [52160/53386 (98%)]	Loss: 1.457139
Train Epoch: 1 [52480/53386 (98%)]	Loss: 1.429856
Train Epoch: 1 [52800/53386 (99%)]	Loss: 1.433700
Train Epoch: 1 [53120/53386 (100%)]	Loss: 1.426310
0.1572570317279681
0.11631022321394544
[[   0    0 1504    0    0    0    0  909]
 [   0    0   95    0    0    0    0 1006]
 [   0    0 1456    0    0    0    0 1884]
 [   0    0  322    0    0    0    0  407]
 [   0    0   74    0    0    0    0  208]
 [   0    0  180    0    0    0    0  306]
 [   0    0  543    0    0    0    0  780]
 [   0    0 1008    0    0    0    0 4659]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.1572570317279681
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 2 [320/53386 (1%)]	Loss: 1.670527
Train Epoch: 2 [640/53386 (1%)]	Loss: 1.471999
Train Epoch: 2 [960/53386 (2%)]	Loss: 1.425239
Train Epoch: 2 [1280/53386 (2%)]	Loss: 1.497685
Train Epoch: 2 [1600/53386 (3%)]	Loss: 1.430868
Train Epoch: 2 [1920/53386 (4%)]	Loss: 1.505279
Train Epoch: 2 [2240/53386 (4%)]	Loss: 1.422387
Train Epoch: 2 [2560/53386 (5%)]	Loss: 1.309951
Train Epoch: 2 [2880/53386 (5%)]	Loss: 1.446408
Train Epoch: 2 [3200/53386 (6%)]	Loss: 1.429944
Train Epoch: 2 [3520/53386 (7%)]	Loss: 1.434873
Train Epoch: 2 [3840/53386 (7%)]	Loss: 1.516342
Train Epoch: 2 [4160/53386 (8%)]	Loss: 1.339022
Train Epoch: 2 [4480/53386 (8%)]	Loss: 1.496514
Train Epoch: 2 [4800/53386 (9%)]	Loss: 1.522300
Train Epoch: 2 [5120/53386 (10%)]	Loss: 1.438596
Train Epoch: 2 [5440/53386 (10%)]	Loss: 1.535372
Train Epoch: 2 [5760/53386 (11%)]	Loss: 1.467863
Train Epoch: 2 [6080/53386 (11%)]	Loss: 1.470700
Train Epoch: 2 [6400/53386 (12%)]	Loss: 1.502163
Train Epoch: 2 [6720/53386 (13%)]	Loss: 1.383938
Train Epoch: 2 [7040/53386 (13%)]	Loss: 1.433691
Train Epoch: 2 [7360/53386 (14%)]	Loss: 1.437175
Train Epoch: 2 [7680/53386 (14%)]	Loss: 1.416896
Train Epoch: 2 [8000/53386 (15%)]	Loss: 1.438794
Train Epoch: 2 [8320/53386 (16%)]	Loss: 1.391596
Train Epoch: 2 [8640/53386 (16%)]	Loss: 1.410357
Train Epoch: 2 [8960/53386 (17%)]	Loss: 1.343962
Train Epoch: 2 [9280/53386 (17%)]	Loss: 1.534358
Train Epoch: 2 [9600/53386 (18%)]	Loss: 1.410035
Train Epoch: 2 [9920/53386 (19%)]	Loss: 1.365381
Train Epoch: 2 [10240/53386 (19%)]	Loss: 1.499810
Train Epoch: 2 [10560/53386 (20%)]	Loss: 1.403023
Train Epoch: 2 [10880/53386 (20%)]	Loss: 1.473370
Train Epoch: 2 [11200/53386 (21%)]	Loss: 1.402006
Train Epoch: 2 [11520/53386 (22%)]	Loss: 1.508990
Train Epoch: 2 [11840/53386 (22%)]	Loss: 1.360174
Train Epoch: 2 [12160/53386 (23%)]	Loss: 1.424909
Train Epoch: 2 [12480/53386 (23%)]	Loss: 1.411164
Train Epoch: 2 [12800/53386 (24%)]	Loss: 1.476981
Train Epoch: 2 [13120/53386 (25%)]	Loss: 1.482789
Train Epoch: 2 [13440/53386 (25%)]	Loss: 1.482892
Train Epoch: 2 [13760/53386 (26%)]	Loss: 1.393424
Train Epoch: 2 [14080/53386 (26%)]	Loss: 1.458782
Train Epoch: 2 [14400/53386 (27%)]	Loss: 1.336359
Train Epoch: 2 [14720/53386 (28%)]	Loss: 1.429353
Train Epoch: 2 [15040/53386 (28%)]	Loss: 1.541839
Train Epoch: 2 [15360/53386 (29%)]	Loss: 1.415781
Train Epoch: 2 [15680/53386 (29%)]	Loss: 1.423206
Train Epoch: 2 [16000/53386 (30%)]	Loss: 1.388212
Train Epoch: 2 [16320/53386 (31%)]	Loss: 1.473343
Train Epoch: 2 [16640/53386 (31%)]	Loss: 1.452199
Train Epoch: 2 [16960/53386 (32%)]	Loss: 1.485997
Train Epoch: 2 [17280/53386 (32%)]	Loss: 1.508388
Train Epoch: 2 [17600/53386 (33%)]	Loss: 1.389091
Train Epoch: 2 [17920/53386 (34%)]	Loss: 1.455673
Train Epoch: 2 [18240/53386 (34%)]	Loss: 1.370991
Train Epoch: 2 [18560/53386 (35%)]	Loss: 1.410096
Train Epoch: 2 [18880/53386 (35%)]	Loss: 1.344171
Train Epoch: 2 [19200/53386 (36%)]	Loss: 1.436831
Train Epoch: 2 [19520/53386 (37%)]	Loss: 1.394120
Train Epoch: 2 [19840/53386 (37%)]	Loss: 1.338103
Train Epoch: 2 [20160/53386 (38%)]	Loss: 1.421269
Train Epoch: 2 [20480/53386 (38%)]	Loss: 1.455483
Train Epoch: 2 [20800/53386 (39%)]	Loss: 1.473637
Train Epoch: 2 [21120/53386 (40%)]	Loss: 1.502611
Train Epoch: 2 [21440/53386 (40%)]	Loss: 1.371468
Train Epoch: 2 [21760/53386 (41%)]	Loss: 1.465337
Train Epoch: 2 [22080/53386 (41%)]	Loss: 1.393834
Train Epoch: 2 [22400/53386 (42%)]	Loss: 1.418775
Train Epoch: 2 [22720/53386 (43%)]	Loss: 1.423116
Train Epoch: 2 [23040/53386 (43%)]	Loss: 1.356985
Train Epoch: 2 [23360/53386 (44%)]	Loss: 1.315849
Train Epoch: 2 [23680/53386 (44%)]	Loss: 1.363151
Train Epoch: 2 [24000/53386 (45%)]	Loss: 1.436014
Train Epoch: 2 [24320/53386 (46%)]	Loss: 1.453501
Train Epoch: 2 [24640/53386 (46%)]	Loss: 1.493439
Train Epoch: 2 [24960/53386 (47%)]	Loss: 1.413553
Train Epoch: 2 [25280/53386 (47%)]	Loss: 1.341399
Train Epoch: 2 [25600/53386 (48%)]	Loss: 1.451129
Train Epoch: 2 [25920/53386 (49%)]	Loss: 1.423605
Train Epoch: 2 [26240/53386 (49%)]	Loss: 1.395306
Train Epoch: 2 [26560/53386 (50%)]	Loss: 1.355329
Train Epoch: 2 [26880/53386 (50%)]	Loss: 1.422288
Train Epoch: 2 [27200/53386 (51%)]	Loss: 1.300923
Train Epoch: 2 [27520/53386 (52%)]	Loss: 1.438844
Train Epoch: 2 [27840/53386 (52%)]	Loss: 1.349169
Train Epoch: 2 [28160/53386 (53%)]	Loss: 1.412998
Train Epoch: 2 [28480/53386 (53%)]	Loss: 1.434529
Train Epoch: 2 [28800/53386 (54%)]	Loss: 1.372529
Train Epoch: 2 [29120/53386 (55%)]	Loss: 1.487950
Train Epoch: 2 [29440/53386 (55%)]	Loss: 1.436572
Train Epoch: 2 [29760/53386 (56%)]	Loss: 1.485892
Train Epoch: 2 [30080/53386 (56%)]	Loss: 1.492618
Train Epoch: 2 [30400/53386 (57%)]	Loss: 1.411082
Train Epoch: 2 [30720/53386 (58%)]	Loss: 1.440383
Train Epoch: 2 [31040/53386 (58%)]	Loss: 1.374167
Train Epoch: 2 [31360/53386 (59%)]	Loss: 1.407244
Train Epoch: 2 [31680/53386 (59%)]	Loss: 1.384594
Train Epoch: 2 [32000/53386 (60%)]	Loss: 1.390822
Train Epoch: 2 [32320/53386 (61%)]	Loss: 1.346093
Train Epoch: 2 [32640/53386 (61%)]	Loss: 1.378280
Train Epoch: 2 [32960/53386 (62%)]	Loss: 1.477524
Train Epoch: 2 [33280/53386 (62%)]	Loss: 1.293874
Train Epoch: 2 [33600/53386 (63%)]	Loss: 1.385947
Train Epoch: 2 [33920/53386 (64%)]	Loss: 1.405139
Train Epoch: 2 [34240/53386 (64%)]	Loss: 1.295910
Train Epoch: 2 [34560/53386 (65%)]	Loss: 1.408497
Train Epoch: 2 [34880/53386 (65%)]	Loss: 1.434988
Train Epoch: 2 [35200/53386 (66%)]	Loss: 1.420504
Train Epoch: 2 [35520/53386 (67%)]	Loss: 1.532660
Train Epoch: 2 [35840/53386 (67%)]	Loss: 1.410079
Train Epoch: 2 [36160/53386 (68%)]	Loss: 1.459754
Train Epoch: 2 [36480/53386 (68%)]	Loss: 1.439217
Train Epoch: 2 [36800/53386 (69%)]	Loss: 1.465986
Train Epoch: 2 [37120/53386 (70%)]	Loss: 1.481336
Train Epoch: 2 [37440/53386 (70%)]	Loss: 1.395570
Train Epoch: 2 [37760/53386 (71%)]	Loss: 1.461479
Train Epoch: 2 [38080/53386 (71%)]	Loss: 1.406190
Train Epoch: 2 [38400/53386 (72%)]	Loss: 1.456879
Train Epoch: 2 [38720/53386 (73%)]	Loss: 1.472056
Train Epoch: 2 [39040/53386 (73%)]	Loss: 1.385117
Train Epoch: 2 [39360/53386 (74%)]	Loss: 1.399531
Train Epoch: 2 [39680/53386 (74%)]	Loss: 1.442841
Train Epoch: 2 [40000/53386 (75%)]	Loss: 1.434085
Train Epoch: 2 [40320/53386 (76%)]	Loss: 1.375422
Train Epoch: 2 [40640/53386 (76%)]	Loss: 1.348282
Train Epoch: 2 [40960/53386 (77%)]	Loss: 1.361236
Train Epoch: 2 [41280/53386 (77%)]	Loss: 1.422787
Train Epoch: 2 [41600/53386 (78%)]	Loss: 1.401783
Train Epoch: 2 [41920/53386 (79%)]	Loss: 1.363686
Train Epoch: 2 [42240/53386 (79%)]	Loss: 1.395960
Train Epoch: 2 [42560/53386 (80%)]	Loss: 1.448638
Train Epoch: 2 [42880/53386 (80%)]	Loss: 1.388281
Train Epoch: 2 [43200/53386 (81%)]	Loss: 1.398180
Train Epoch: 2 [43520/53386 (82%)]	Loss: 1.312188
Train Epoch: 2 [43840/53386 (82%)]	Loss: 1.432702
Train Epoch: 2 [44160/53386 (83%)]	Loss: 1.419673
Train Epoch: 2 [44480/53386 (83%)]	Loss: 1.402643
Train Epoch: 2 [44800/53386 (84%)]	Loss: 1.415146
Train Epoch: 2 [45120/53386 (85%)]	Loss: 1.342083
Train Epoch: 2 [45440/53386 (85%)]	Loss: 1.427947
Train Epoch: 2 [45760/53386 (86%)]	Loss: 1.425485
Train Epoch: 2 [46080/53386 (86%)]	Loss: 1.509501
Train Epoch: 2 [46400/53386 (87%)]	Loss: 1.401004
Train Epoch: 2 [46720/53386 (88%)]	Loss: 1.376597
Train Epoch: 2 [47040/53386 (88%)]	Loss: 1.467177
Train Epoch: 2 [47360/53386 (89%)]	Loss: 1.388667
Train Epoch: 2 [47680/53386 (89%)]	Loss: 1.333466
Train Epoch: 2 [48000/53386 (90%)]	Loss: 1.342722
Train Epoch: 2 [48320/53386 (91%)]	Loss: 1.407488
Train Epoch: 2 [48640/53386 (91%)]	Loss: 1.417229
Train Epoch: 2 [48960/53386 (92%)]	Loss: 1.428377
Train Epoch: 2 [49280/53386 (92%)]	Loss: 1.559040
Train Epoch: 2 [49600/53386 (93%)]	Loss: 1.384795
Train Epoch: 2 [49920/53386 (94%)]	Loss: 1.359138
Train Epoch: 2 [50240/53386 (94%)]	Loss: 1.349959
Train Epoch: 2 [50560/53386 (95%)]	Loss: 1.407673
Train Epoch: 2 [50880/53386 (95%)]	Loss: 1.453443
Train Epoch: 2 [51200/53386 (96%)]	Loss: 1.324395
Train Epoch: 2 [51520/53386 (97%)]	Loss: 1.442463
Train Epoch: 2 [51840/53386 (97%)]	Loss: 1.390000
Train Epoch: 2 [52160/53386 (98%)]	Loss: 1.453390
Train Epoch: 2 [52480/53386 (98%)]	Loss: 1.303630
Train Epoch: 2 [52800/53386 (99%)]	Loss: 1.400956
Train Epoch: 2 [53120/53386 (100%)]	Loss: 1.522776
0.2197425194861023
0.18885503367949108
[[1491    0  167    0    0    0    0  755]
 [  72    0   31    0    0    0    0  998]
 [ 326    0 1096    0    0    0    0 1918]
 [ 167    0  163    0    0    0    0  399]
 [  47    0   31    0    0    0    0  204]
 [ 128    0   57    0    0    0    0  301]
 [ 480    0  111    0    0    0    0  732]
 [ 788    0  278    0    0    0    0 4601]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.2197425194861023
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 3 [320/53386 (1%)]	Loss: 1.493549
Train Epoch: 3 [640/53386 (1%)]	Loss: 1.421770
Train Epoch: 3 [960/53386 (2%)]	Loss: 1.483347
Train Epoch: 3 [1280/53386 (2%)]	Loss: 1.436810
Train Epoch: 3 [1600/53386 (3%)]	Loss: 1.359598
Train Epoch: 3 [1920/53386 (4%)]	Loss: 1.394775
Train Epoch: 3 [2240/53386 (4%)]	Loss: 1.395468
Train Epoch: 3 [2560/53386 (5%)]	Loss: 1.522490
Train Epoch: 3 [2880/53386 (5%)]	Loss: 1.342675
Train Epoch: 3 [3200/53386 (6%)]	Loss: 1.338262
Train Epoch: 3 [3520/53386 (7%)]	Loss: 1.530957
Train Epoch: 3 [3840/53386 (7%)]	Loss: 1.386683
Train Epoch: 3 [4160/53386 (8%)]	Loss: 1.438368
Train Epoch: 3 [4480/53386 (8%)]	Loss: 1.267825
Train Epoch: 3 [4800/53386 (9%)]	Loss: 1.406436
Train Epoch: 3 [5120/53386 (10%)]	Loss: 1.431517
Train Epoch: 3 [5440/53386 (10%)]	Loss: 1.393946
Train Epoch: 3 [5760/53386 (11%)]	Loss: 1.359255
Train Epoch: 3 [6080/53386 (11%)]	Loss: 1.408431
Train Epoch: 3 [6400/53386 (12%)]	Loss: 1.301751
Train Epoch: 3 [6720/53386 (13%)]	Loss: 1.316901
Train Epoch: 3 [7040/53386 (13%)]	Loss: 1.375654
Train Epoch: 3 [7360/53386 (14%)]	Loss: 1.300569
Train Epoch: 3 [7680/53386 (14%)]	Loss: 1.447946
Train Epoch: 3 [8000/53386 (15%)]	Loss: 1.381797
Train Epoch: 3 [8320/53386 (16%)]	Loss: 1.369805
Train Epoch: 3 [8640/53386 (16%)]	Loss: 1.401626
Train Epoch: 3 [8960/53386 (17%)]	Loss: 1.310769
Train Epoch: 3 [9280/53386 (17%)]	Loss: 1.361671
Train Epoch: 3 [9600/53386 (18%)]	Loss: 1.486127
Train Epoch: 3 [9920/53386 (19%)]	Loss: 1.398422
Train Epoch: 3 [10240/53386 (19%)]	Loss: 1.361259
Train Epoch: 3 [10560/53386 (20%)]	Loss: 1.429232
Train Epoch: 3 [10880/53386 (20%)]	Loss: 1.431913
Train Epoch: 3 [11200/53386 (21%)]	Loss: 1.306826
Train Epoch: 3 [11520/53386 (22%)]	Loss: 1.310403
Train Epoch: 3 [11840/53386 (22%)]	Loss: 1.380582
Train Epoch: 3 [12160/53386 (23%)]	Loss: 1.326681
Train Epoch: 3 [12480/53386 (23%)]	Loss: 1.412413
Train Epoch: 3 [12800/53386 (24%)]	Loss: 1.318677
Train Epoch: 3 [13120/53386 (25%)]	Loss: 1.402162
Train Epoch: 3 [13440/53386 (25%)]	Loss: 1.414869
Train Epoch: 3 [13760/53386 (26%)]	Loss: 1.320781
Train Epoch: 3 [14080/53386 (26%)]	Loss: 1.380689
Train Epoch: 3 [14400/53386 (27%)]	Loss: 1.451136
Train Epoch: 3 [14720/53386 (28%)]	Loss: 1.355532
Train Epoch: 3 [15040/53386 (28%)]	Loss: 1.367921
Train Epoch: 3 [15360/53386 (29%)]	Loss: 1.347902
Train Epoch: 3 [15680/53386 (29%)]	Loss: 1.366072
Train Epoch: 3 [16000/53386 (30%)]	Loss: 1.262300
Train Epoch: 3 [16320/53386 (31%)]	Loss: 1.404129
Train Epoch: 3 [16640/53386 (31%)]	Loss: 1.284671
Train Epoch: 3 [16960/53386 (32%)]	Loss: 1.449608
Train Epoch: 3 [17280/53386 (32%)]	Loss: 1.383362
Train Epoch: 3 [17600/53386 (33%)]	Loss: 1.429983
Train Epoch: 3 [17920/53386 (34%)]	Loss: 1.348184
Train Epoch: 3 [18240/53386 (34%)]	Loss: 1.489695
Train Epoch: 3 [18560/53386 (35%)]	Loss: 1.375987
Train Epoch: 3 [18880/53386 (35%)]	Loss: 1.291670
Train Epoch: 3 [19200/53386 (36%)]	Loss: 1.288063
Train Epoch: 3 [19520/53386 (37%)]	Loss: 1.436175
Train Epoch: 3 [19840/53386 (37%)]	Loss: 1.362163
Train Epoch: 3 [20160/53386 (38%)]	Loss: 1.347092
Train Epoch: 3 [20480/53386 (38%)]	Loss: 1.463781
Train Epoch: 3 [20800/53386 (39%)]	Loss: 1.305803
Train Epoch: 3 [21120/53386 (40%)]	Loss: 1.409518
Train Epoch: 3 [21440/53386 (40%)]	Loss: 1.383380
Train Epoch: 3 [21760/53386 (41%)]	Loss: 1.446171
Train Epoch: 3 [22080/53386 (41%)]	Loss: 1.393037
Train Epoch: 3 [22400/53386 (42%)]	Loss: 1.407131
Train Epoch: 3 [22720/53386 (43%)]	Loss: 1.396997
Train Epoch: 3 [23040/53386 (43%)]	Loss: 1.443987
Train Epoch: 3 [23360/53386 (44%)]	Loss: 1.375087
Train Epoch: 3 [23680/53386 (44%)]	Loss: 1.422078
Train Epoch: 3 [24000/53386 (45%)]	Loss: 1.507257
Train Epoch: 3 [24320/53386 (46%)]	Loss: 1.322440
Train Epoch: 3 [24640/53386 (46%)]	Loss: 1.348593
Train Epoch: 3 [24960/53386 (47%)]	Loss: 1.453726
Train Epoch: 3 [25280/53386 (47%)]	Loss: 1.401756
Train Epoch: 3 [25600/53386 (48%)]	Loss: 1.408010
Train Epoch: 3 [25920/53386 (49%)]	Loss: 1.294924
Train Epoch: 3 [26240/53386 (49%)]	Loss: 1.303588
Train Epoch: 3 [26560/53386 (50%)]	Loss: 1.400675
Train Epoch: 3 [26880/53386 (50%)]	Loss: 1.418988
Train Epoch: 3 [27200/53386 (51%)]	Loss: 1.476974
Train Epoch: 3 [27520/53386 (52%)]	Loss: 1.439758
Train Epoch: 3 [27840/53386 (52%)]	Loss: 1.371489
Train Epoch: 3 [28160/53386 (53%)]	Loss: 1.423423
Train Epoch: 3 [28480/53386 (53%)]	Loss: 1.392126
Train Epoch: 3 [28800/53386 (54%)]	Loss: 1.326180
Train Epoch: 3 [29120/53386 (55%)]	Loss: 1.409680
Train Epoch: 3 [29440/53386 (55%)]	Loss: 1.334337
Train Epoch: 3 [29760/53386 (56%)]	Loss: 1.481606
Train Epoch: 3 [30080/53386 (56%)]	Loss: 1.402461
Train Epoch: 3 [30400/53386 (57%)]	Loss: 1.371137
Train Epoch: 3 [30720/53386 (58%)]	Loss: 1.318575
Train Epoch: 3 [31040/53386 (58%)]	Loss: 1.419847
Train Epoch: 3 [31360/53386 (59%)]	Loss: 1.347820
Train Epoch: 3 [31680/53386 (59%)]	Loss: 1.435027
Train Epoch: 3 [32000/53386 (60%)]	Loss: 1.355137
Train Epoch: 3 [32320/53386 (61%)]	Loss: 1.359409
Train Epoch: 3 [32640/53386 (61%)]	Loss: 1.261140
Train Epoch: 3 [32960/53386 (62%)]	Loss: 1.304988
Train Epoch: 3 [33280/53386 (62%)]	Loss: 1.333628
Train Epoch: 3 [33600/53386 (63%)]	Loss: 1.351678
Train Epoch: 3 [33920/53386 (64%)]	Loss: 1.359611
Train Epoch: 3 [34240/53386 (64%)]	Loss: 1.334358
Train Epoch: 3 [34560/53386 (65%)]	Loss: 1.448018
Train Epoch: 3 [34880/53386 (65%)]	Loss: 1.394660
Train Epoch: 3 [35200/53386 (66%)]	Loss: 1.339634
Train Epoch: 3 [35520/53386 (67%)]	Loss: 1.377477
Train Epoch: 3 [35840/53386 (67%)]	Loss: 1.377573
Train Epoch: 3 [36160/53386 (68%)]	Loss: 1.346955
Train Epoch: 3 [36480/53386 (68%)]	Loss: 1.446614
Train Epoch: 3 [36800/53386 (69%)]	Loss: 1.419605
Train Epoch: 3 [37120/53386 (70%)]	Loss: 1.392402
Train Epoch: 3 [37440/53386 (70%)]	Loss: 1.365908
Train Epoch: 3 [37760/53386 (71%)]	Loss: 1.428038
Train Epoch: 3 [38080/53386 (71%)]	Loss: 1.308401
Train Epoch: 3 [38400/53386 (72%)]	Loss: 1.338104
Train Epoch: 3 [38720/53386 (73%)]	Loss: 1.354663
Train Epoch: 3 [39040/53386 (73%)]	Loss: 1.389970
Train Epoch: 3 [39360/53386 (74%)]	Loss: 1.269457
Train Epoch: 3 [39680/53386 (74%)]	Loss: 1.375727
Train Epoch: 3 [40000/53386 (75%)]	Loss: 1.345330
Train Epoch: 3 [40320/53386 (76%)]	Loss: 1.411896
Train Epoch: 3 [40640/53386 (76%)]	Loss: 1.368941
Train Epoch: 3 [40960/53386 (77%)]	Loss: 1.322812
Train Epoch: 3 [41280/53386 (77%)]	Loss: 1.346874
Train Epoch: 3 [41600/53386 (78%)]	Loss: 1.358579
Train Epoch: 3 [41920/53386 (79%)]	Loss: 1.345784
Train Epoch: 3 [42240/53386 (79%)]	Loss: 1.316524
Train Epoch: 3 [42560/53386 (80%)]	Loss: 1.471203
Train Epoch: 3 [42880/53386 (80%)]	Loss: 1.460477
Train Epoch: 3 [43200/53386 (81%)]	Loss: 1.331876
Train Epoch: 3 [43520/53386 (82%)]	Loss: 1.385273
Train Epoch: 3 [43840/53386 (82%)]	Loss: 1.428246
Train Epoch: 3 [44160/53386 (83%)]	Loss: 1.300514
Train Epoch: 3 [44480/53386 (83%)]	Loss: 1.361077
Train Epoch: 3 [44800/53386 (84%)]	Loss: 1.492561
Train Epoch: 3 [45120/53386 (85%)]	Loss: 1.398582
Train Epoch: 3 [45440/53386 (85%)]	Loss: 1.278873
Train Epoch: 3 [45760/53386 (86%)]	Loss: 1.370269
Train Epoch: 3 [46080/53386 (86%)]	Loss: 1.395773
Train Epoch: 3 [46400/53386 (87%)]	Loss: 1.351011
Train Epoch: 3 [46720/53386 (88%)]	Loss: 1.334167
Train Epoch: 3 [47040/53386 (88%)]	Loss: 1.458283
Train Epoch: 3 [47360/53386 (89%)]	Loss: 1.301156
Train Epoch: 3 [47680/53386 (89%)]	Loss: 1.341581
Train Epoch: 3 [48000/53386 (90%)]	Loss: 1.322349
Train Epoch: 3 [48320/53386 (91%)]	Loss: 1.324889
Train Epoch: 3 [48640/53386 (91%)]	Loss: 1.401633
Train Epoch: 3 [48960/53386 (92%)]	Loss: 1.346791
Train Epoch: 3 [49280/53386 (92%)]	Loss: 1.332566
Train Epoch: 3 [49600/53386 (93%)]	Loss: 1.247303
Train Epoch: 3 [49920/53386 (94%)]	Loss: 1.369444
Train Epoch: 3 [50240/53386 (94%)]	Loss: 1.435513
Train Epoch: 3 [50560/53386 (95%)]	Loss: 1.387675
Train Epoch: 3 [50880/53386 (95%)]	Loss: 1.426210
Train Epoch: 3 [51200/53386 (96%)]	Loss: 1.404484
Train Epoch: 3 [51520/53386 (97%)]	Loss: 1.297391
Train Epoch: 3 [51840/53386 (97%)]	Loss: 1.392155
Train Epoch: 3 [52160/53386 (98%)]	Loss: 1.320976
Train Epoch: 3 [52480/53386 (98%)]	Loss: 1.274887
Train Epoch: 3 [52800/53386 (99%)]	Loss: 1.392868
Train Epoch: 3 [53120/53386 (100%)]	Loss: 1.327688
0.23320815133508344
0.20255070056340707
[[1539    0  125    0    0    0    0  749]
 [  67    0   42    0    0    0    0  992]
 [ 275    0 1476    0    0    0    0 1589]
 [ 167    0  179    0    0    0    0  383]
 [  55    0   28    0    0    0    0  199]
 [ 155    0   42    0    0    0    0  289]
 [ 501    0  119    0    0    0    0  703]
 [ 790    0  423    0    0    0    0 4454]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.23320815133508344
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 4 [320/53386 (1%)]	Loss: 1.406160
Train Epoch: 4 [640/53386 (1%)]	Loss: 1.244516
Train Epoch: 4 [960/53386 (2%)]	Loss: 1.366562
Train Epoch: 4 [1280/53386 (2%)]	Loss: 1.342566
Train Epoch: 4 [1600/53386 (3%)]	Loss: 1.375706
Train Epoch: 4 [1920/53386 (4%)]	Loss: 1.324272
Train Epoch: 4 [2240/53386 (4%)]	Loss: 1.277275
Train Epoch: 4 [2560/53386 (5%)]	Loss: 1.340491
Train Epoch: 4 [2880/53386 (5%)]	Loss: 1.313016
Train Epoch: 4 [3200/53386 (6%)]	Loss: 1.370912
Train Epoch: 4 [3520/53386 (7%)]	Loss: 1.433338
Train Epoch: 4 [3840/53386 (7%)]	Loss: 1.319587
Train Epoch: 4 [4160/53386 (8%)]	Loss: 1.310262
Train Epoch: 4 [4480/53386 (8%)]	Loss: 1.249813
Train Epoch: 4 [4800/53386 (9%)]	Loss: 1.220926
Train Epoch: 4 [5120/53386 (10%)]	Loss: 1.267399
Train Epoch: 4 [5440/53386 (10%)]	Loss: 1.393709
Train Epoch: 4 [5760/53386 (11%)]	Loss: 1.312374
Train Epoch: 4 [6080/53386 (11%)]	Loss: 1.306898
Train Epoch: 4 [6400/53386 (12%)]	Loss: 1.327299
Train Epoch: 4 [6720/53386 (13%)]	Loss: 1.395560
Train Epoch: 4 [7040/53386 (13%)]	Loss: 1.359274
Train Epoch: 4 [7360/53386 (14%)]	Loss: 1.448593
Train Epoch: 4 [7680/53386 (14%)]	Loss: 1.344237
Train Epoch: 4 [8000/53386 (15%)]	Loss: 1.228083
Train Epoch: 4 [8320/53386 (16%)]	Loss: 1.313235
Train Epoch: 4 [8640/53386 (16%)]	Loss: 1.222755
Train Epoch: 4 [8960/53386 (17%)]	Loss: 1.310201
Train Epoch: 4 [9280/53386 (17%)]	Loss: 1.404513
Train Epoch: 4 [9600/53386 (18%)]	Loss: 1.452387
Train Epoch: 4 [9920/53386 (19%)]	Loss: 1.432263
Train Epoch: 4 [10240/53386 (19%)]	Loss: 1.348446
Train Epoch: 4 [10560/53386 (20%)]	Loss: 1.288567
Train Epoch: 4 [10880/53386 (20%)]	Loss: 1.305389
Train Epoch: 4 [11200/53386 (21%)]	Loss: 1.411631
Train Epoch: 4 [11520/53386 (22%)]	Loss: 1.392591
Train Epoch: 4 [11840/53386 (22%)]	Loss: 1.405313
Train Epoch: 4 [12160/53386 (23%)]	Loss: 1.410146
Train Epoch: 4 [12480/53386 (23%)]	Loss: 1.324413
Train Epoch: 4 [12800/53386 (24%)]	Loss: 1.390215
Train Epoch: 4 [13120/53386 (25%)]	Loss: 1.325709
Train Epoch: 4 [13440/53386 (25%)]	Loss: 1.392460
Train Epoch: 4 [13760/53386 (26%)]	Loss: 1.420918
Train Epoch: 4 [14080/53386 (26%)]	Loss: 1.413005
Train Epoch: 4 [14400/53386 (27%)]	Loss: 1.291768
Train Epoch: 4 [14720/53386 (28%)]	Loss: 1.370016
Train Epoch: 4 [15040/53386 (28%)]	Loss: 1.272573
Train Epoch: 4 [15360/53386 (29%)]	Loss: 1.400953
Train Epoch: 4 [15680/53386 (29%)]	Loss: 1.323337
Train Epoch: 4 [16000/53386 (30%)]	Loss: 1.307320
Train Epoch: 4 [16320/53386 (31%)]	Loss: 1.357694
Train Epoch: 4 [16640/53386 (31%)]	Loss: 1.293795
Train Epoch: 4 [16960/53386 (32%)]	Loss: 1.209519
Train Epoch: 4 [17280/53386 (32%)]	Loss: 1.357762
Train Epoch: 4 [17600/53386 (33%)]	Loss: 1.349514
Train Epoch: 4 [17920/53386 (34%)]	Loss: 1.471787
Train Epoch: 4 [18240/53386 (34%)]	Loss: 1.298535
Train Epoch: 4 [18560/53386 (35%)]	Loss: 1.343099
Train Epoch: 4 [18880/53386 (35%)]	Loss: 1.515193
Train Epoch: 4 [19200/53386 (36%)]	Loss: 1.347165
Train Epoch: 4 [19520/53386 (37%)]	Loss: 1.437431
Train Epoch: 4 [19840/53386 (37%)]	Loss: 1.301859
Train Epoch: 4 [20160/53386 (38%)]	Loss: 1.208380
Train Epoch: 4 [20480/53386 (38%)]	Loss: 1.415748
Train Epoch: 4 [20800/53386 (39%)]	Loss: 1.133080
Train Epoch: 4 [21120/53386 (40%)]	Loss: 1.174744
Train Epoch: 4 [21440/53386 (40%)]	Loss: 1.386886
Train Epoch: 4 [21760/53386 (41%)]	Loss: 1.289166
Train Epoch: 4 [22080/53386 (41%)]	Loss: 1.303025
Train Epoch: 4 [22400/53386 (42%)]	Loss: 1.390159
Train Epoch: 4 [22720/53386 (43%)]	Loss: 1.276817
Train Epoch: 4 [23040/53386 (43%)]	Loss: 1.286485
Train Epoch: 4 [23360/53386 (44%)]	Loss: 1.294982
Train Epoch: 4 [23680/53386 (44%)]	Loss: 1.263523
Train Epoch: 4 [24000/53386 (45%)]	Loss: 1.298681
Train Epoch: 4 [24320/53386 (46%)]	Loss: 1.367309
Train Epoch: 4 [24640/53386 (46%)]	Loss: 1.395955
Train Epoch: 4 [24960/53386 (47%)]	Loss: 1.254946
Train Epoch: 4 [25280/53386 (47%)]	Loss: 1.376573
Train Epoch: 4 [25600/53386 (48%)]	Loss: 1.326983
Train Epoch: 4 [25920/53386 (49%)]	Loss: 1.410221
Train Epoch: 4 [26240/53386 (49%)]	Loss: 1.336295
Train Epoch: 4 [26560/53386 (50%)]	Loss: 1.455287
Train Epoch: 4 [26880/53386 (50%)]	Loss: 1.294131
Train Epoch: 4 [27200/53386 (51%)]	Loss: 1.266020
Train Epoch: 4 [27520/53386 (52%)]	Loss: 1.395800
Train Epoch: 4 [27840/53386 (52%)]	Loss: 1.445469
Train Epoch: 4 [28160/53386 (53%)]	Loss: 1.368903
Train Epoch: 4 [28480/53386 (53%)]	Loss: 1.298112
Train Epoch: 4 [28800/53386 (54%)]	Loss: 1.291563
Train Epoch: 4 [29120/53386 (55%)]	Loss: 1.343354
Train Epoch: 4 [29440/53386 (55%)]	Loss: 1.379334
Train Epoch: 4 [29760/53386 (56%)]	Loss: 1.390420
Train Epoch: 4 [30080/53386 (56%)]	Loss: 1.241366
Train Epoch: 4 [30400/53386 (57%)]	Loss: 1.259463
Train Epoch: 4 [30720/53386 (58%)]	Loss: 1.396803
Train Epoch: 4 [31040/53386 (58%)]	Loss: 1.305867
Train Epoch: 4 [31360/53386 (59%)]	Loss: 1.334887
Train Epoch: 4 [31680/53386 (59%)]	Loss: 1.380964
Train Epoch: 4 [32000/53386 (60%)]	Loss: 1.352066
Train Epoch: 4 [32320/53386 (61%)]	Loss: 1.321367
Train Epoch: 4 [32640/53386 (61%)]	Loss: 1.406099
Train Epoch: 4 [32960/53386 (62%)]	Loss: 1.285255
Train Epoch: 4 [33280/53386 (62%)]	Loss: 1.377601
Train Epoch: 4 [33600/53386 (63%)]	Loss: 1.368139
Train Epoch: 4 [33920/53386 (64%)]	Loss: 1.369722
Train Epoch: 4 [34240/53386 (64%)]	Loss: 1.333447
Train Epoch: 4 [34560/53386 (65%)]	Loss: 1.231620
Train Epoch: 4 [34880/53386 (65%)]	Loss: 1.382637
Train Epoch: 4 [35200/53386 (66%)]	Loss: 1.293817
Train Epoch: 4 [35520/53386 (67%)]	Loss: 1.291090
Train Epoch: 4 [35840/53386 (67%)]	Loss: 1.395540
Train Epoch: 4 [36160/53386 (68%)]	Loss: 1.389707
Train Epoch: 4 [36480/53386 (68%)]	Loss: 1.343248
Train Epoch: 4 [36800/53386 (69%)]	Loss: 1.296038
Train Epoch: 4 [37120/53386 (70%)]	Loss: 1.386510
Train Epoch: 4 [37440/53386 (70%)]	Loss: 1.343603
Train Epoch: 4 [37760/53386 (71%)]	Loss: 1.394451
Train Epoch: 4 [38080/53386 (71%)]	Loss: 1.439892
Train Epoch: 4 [38400/53386 (72%)]	Loss: 1.416353
Train Epoch: 4 [38720/53386 (73%)]	Loss: 1.309770
Train Epoch: 4 [39040/53386 (73%)]	Loss: 1.327516
Train Epoch: 4 [39360/53386 (74%)]	Loss: 1.405252
Train Epoch: 4 [39680/53386 (74%)]	Loss: 1.250191
Train Epoch: 4 [40000/53386 (75%)]	Loss: 1.429984
Train Epoch: 4 [40320/53386 (76%)]	Loss: 1.336991
Train Epoch: 4 [40640/53386 (76%)]	Loss: 1.401665
Train Epoch: 4 [40960/53386 (77%)]	Loss: 1.373009
Train Epoch: 4 [41280/53386 (77%)]	Loss: 1.329156
Train Epoch: 4 [41600/53386 (78%)]	Loss: 1.351764
Train Epoch: 4 [41920/53386 (79%)]	Loss: 1.369440
Train Epoch: 4 [42240/53386 (79%)]	Loss: 1.344445
Train Epoch: 4 [42560/53386 (80%)]	Loss: 1.288246
Train Epoch: 4 [42880/53386 (80%)]	Loss: 1.291797
Train Epoch: 4 [43200/53386 (81%)]	Loss: 1.422773
Train Epoch: 4 [43520/53386 (82%)]	Loss: 1.352982
Train Epoch: 4 [43840/53386 (82%)]	Loss: 1.386240
Train Epoch: 4 [44160/53386 (83%)]	Loss: 1.320537
Train Epoch: 4 [44480/53386 (83%)]	Loss: 1.506350
Train Epoch: 4 [44800/53386 (84%)]	Loss: 1.367981
Train Epoch: 4 [45120/53386 (85%)]	Loss: 1.434126
Train Epoch: 4 [45440/53386 (85%)]	Loss: 1.475195
Train Epoch: 4 [45760/53386 (86%)]	Loss: 1.423562
Train Epoch: 4 [46080/53386 (86%)]	Loss: 1.338970
Train Epoch: 4 [46400/53386 (87%)]	Loss: 1.442468
Train Epoch: 4 [46720/53386 (88%)]	Loss: 1.395235
Train Epoch: 4 [47040/53386 (88%)]	Loss: 1.266689
Train Epoch: 4 [47360/53386 (89%)]	Loss: 1.389902
Train Epoch: 4 [47680/53386 (89%)]	Loss: 1.396624
Train Epoch: 4 [48000/53386 (90%)]	Loss: 1.266372
Train Epoch: 4 [48320/53386 (91%)]	Loss: 1.430751
Train Epoch: 4 [48640/53386 (91%)]	Loss: 1.364580
Train Epoch: 4 [48960/53386 (92%)]	Loss: 1.365894
Train Epoch: 4 [49280/53386 (92%)]	Loss: 1.276424
Train Epoch: 4 [49600/53386 (93%)]	Loss: 1.323477
Train Epoch: 4 [49920/53386 (94%)]	Loss: 1.318567
Train Epoch: 4 [50240/53386 (94%)]	Loss: 1.318105
Train Epoch: 4 [50560/53386 (95%)]	Loss: 1.235253
Train Epoch: 4 [50880/53386 (95%)]	Loss: 1.365605
Train Epoch: 4 [51200/53386 (96%)]	Loss: 1.247309
Train Epoch: 4 [51520/53386 (97%)]	Loss: 1.341102
Train Epoch: 4 [51840/53386 (97%)]	Loss: 1.401546
Train Epoch: 4 [52160/53386 (98%)]	Loss: 1.406372
Train Epoch: 4 [52480/53386 (98%)]	Loss: 1.413710
Train Epoch: 4 [52800/53386 (99%)]	Loss: 1.417902
Train Epoch: 4 [53120/53386 (100%)]	Loss: 1.441407
0.24636875884551146
0.2127269023580877
[[1650    6  216    0    0    0    0  541]
 [  99   34  106    0    0    0    0  862]
 [ 265    2 1974    0    0    0    0 1099]
 [ 155    0  275    0    0    0    0  299]
 [  58    0   59    0    0    0    0  165]
 [ 171    0   83    0    0    0    0  232]
 [ 554    1  219    0    0    0    0  549]
 [ 874   15 1008    0    0    0    0 3770]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.24636875884551146
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 5 [320/53386 (1%)]	Loss: 1.549995
Train Epoch: 5 [640/53386 (1%)]	Loss: 1.211103
Train Epoch: 5 [960/53386 (2%)]	Loss: 1.250117
Train Epoch: 5 [1280/53386 (2%)]	Loss: 1.298067
Train Epoch: 5 [1600/53386 (3%)]	Loss: 1.299842
Train Epoch: 5 [1920/53386 (4%)]	Loss: 1.318151
Train Epoch: 5 [2240/53386 (4%)]	Loss: 1.296436
Train Epoch: 5 [2560/53386 (5%)]	Loss: 1.373648
Train Epoch: 5 [2880/53386 (5%)]	Loss: 1.310324
Train Epoch: 5 [3200/53386 (6%)]	Loss: 1.292257
Train Epoch: 5 [3520/53386 (7%)]	Loss: 1.339948
Train Epoch: 5 [3840/53386 (7%)]	Loss: 1.452888
Train Epoch: 5 [4160/53386 (8%)]	Loss: 1.246073
Train Epoch: 5 [4480/53386 (8%)]	Loss: 1.281395
Train Epoch: 5 [4800/53386 (9%)]	Loss: 1.249875
Train Epoch: 5 [5120/53386 (10%)]	Loss: 1.281213
Train Epoch: 5 [5440/53386 (10%)]	Loss: 1.438055
Train Epoch: 5 [5760/53386 (11%)]	Loss: 1.301977
Train Epoch: 5 [6080/53386 (11%)]	Loss: 1.349474
Train Epoch: 5 [6400/53386 (12%)]	Loss: 1.372607
Train Epoch: 5 [6720/53386 (13%)]	Loss: 1.325881
Train Epoch: 5 [7040/53386 (13%)]	Loss: 1.319606
Train Epoch: 5 [7360/53386 (14%)]	Loss: 1.309127
Train Epoch: 5 [7680/53386 (14%)]	Loss: 1.269916
Train Epoch: 5 [8000/53386 (15%)]	Loss: 1.253720
Train Epoch: 5 [8320/53386 (16%)]	Loss: 1.300307
Train Epoch: 5 [8640/53386 (16%)]	Loss: 1.423108
Train Epoch: 5 [8960/53386 (17%)]	Loss: 1.394534
Train Epoch: 5 [9280/53386 (17%)]	Loss: 1.314983
Train Epoch: 5 [9600/53386 (18%)]	Loss: 1.472968
Train Epoch: 5 [9920/53386 (19%)]	Loss: 1.414141
Train Epoch: 5 [10240/53386 (19%)]	Loss: 1.328574
