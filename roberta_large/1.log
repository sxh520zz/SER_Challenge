nohup: 忽略输入
Some weights of the model checkpoint at /mnt/data1/liyongwei/SSL_Models/facebook/roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 1 [640/53386 (1%)]	Loss: 2.222994
Train Epoch: 1 [1280/53386 (2%)]	Loss: 1.721198
Train Epoch: 1 [1920/53386 (4%)]	Loss: 1.541431
Train Epoch: 1 [2560/53386 (5%)]	Loss: 1.506902
Train Epoch: 1 [3200/53386 (6%)]	Loss: 1.548979
Train Epoch: 1 [3840/53386 (7%)]	Loss: 1.539685
Train Epoch: 1 [4480/53386 (8%)]	Loss: 1.503265
Train Epoch: 1 [5120/53386 (10%)]	Loss: 1.494189
Train Epoch: 1 [5760/53386 (11%)]	Loss: 1.467825
Train Epoch: 1 [6400/53386 (12%)]	Loss: 1.479323
Train Epoch: 1 [7040/53386 (13%)]	Loss: 1.439828
Train Epoch: 1 [7680/53386 (14%)]	Loss: 1.545869
Train Epoch: 1 [8320/53386 (16%)]	Loss: 1.445897
Train Epoch: 1 [8960/53386 (17%)]	Loss: 1.503737
Train Epoch: 1 [9600/53386 (18%)]	Loss: 1.464723
Train Epoch: 1 [10240/53386 (19%)]	Loss: 1.449787
Train Epoch: 1 [10880/53386 (20%)]	Loss: 1.450801
Train Epoch: 1 [11520/53386 (22%)]	Loss: 1.533767
Train Epoch: 1 [12160/53386 (23%)]	Loss: 1.419039
Train Epoch: 1 [12800/53386 (24%)]	Loss: 1.450995
Train Epoch: 1 [13440/53386 (25%)]	Loss: 1.359476
Train Epoch: 1 [14080/53386 (26%)]	Loss: 1.436742
Train Epoch: 1 [14720/53386 (28%)]	Loss: 1.390919
Train Epoch: 1 [15360/53386 (29%)]	Loss: 1.444301
Train Epoch: 1 [16000/53386 (30%)]	Loss: 1.509300
Train Epoch: 1 [16640/53386 (31%)]	Loss: 1.436158
Train Epoch: 1 [17280/53386 (32%)]	Loss: 1.405479
Train Epoch: 1 [17920/53386 (34%)]	Loss: 1.394177
Train Epoch: 1 [18560/53386 (35%)]	Loss: 1.510397
Train Epoch: 1 [19200/53386 (36%)]	Loss: 1.428726
Train Epoch: 1 [19840/53386 (37%)]	Loss: 1.412051
Train Epoch: 1 [20480/53386 (38%)]	Loss: 1.389452
Train Epoch: 1 [21120/53386 (40%)]	Loss: 1.422946
Train Epoch: 1 [21760/53386 (41%)]	Loss: 1.327563
Train Epoch: 1 [22400/53386 (42%)]	Loss: 1.479387
Train Epoch: 1 [23040/53386 (43%)]	Loss: 1.373477
Train Epoch: 1 [23680/53386 (44%)]	Loss: 1.399108
Train Epoch: 1 [24320/53386 (46%)]	Loss: 1.393335
Train Epoch: 1 [24960/53386 (47%)]	Loss: 1.420359
Train Epoch: 1 [25600/53386 (48%)]	Loss: 1.409835
Train Epoch: 1 [26240/53386 (49%)]	Loss: 1.410314
Train Epoch: 1 [26880/53386 (50%)]	Loss: 1.472156
Train Epoch: 1 [27520/53386 (52%)]	Loss: 1.437916
Train Epoch: 1 [28160/53386 (53%)]	Loss: 1.330150
Train Epoch: 1 [28800/53386 (54%)]	Loss: 1.400541
Train Epoch: 1 [29440/53386 (55%)]	Loss: 1.418088
Train Epoch: 1 [30080/53386 (56%)]	Loss: 1.358446
Train Epoch: 1 [30720/53386 (58%)]	Loss: 1.362986
Train Epoch: 1 [31360/53386 (59%)]	Loss: 1.372180
Train Epoch: 1 [32000/53386 (60%)]	Loss: 1.372150
Train Epoch: 1 [32640/53386 (61%)]	Loss: 1.387978
Train Epoch: 1 [33280/53386 (62%)]	Loss: 1.366713
Train Epoch: 1 [33920/53386 (64%)]	Loss: 1.392638
Train Epoch: 1 [34560/53386 (65%)]	Loss: 1.364286
Train Epoch: 1 [35200/53386 (66%)]	Loss: 1.331958
Train Epoch: 1 [35840/53386 (67%)]	Loss: 1.354238
Train Epoch: 1 [36480/53386 (68%)]	Loss: 1.456631
Train Epoch: 1 [37120/53386 (70%)]	Loss: 1.362550
Train Epoch: 1 [37760/53386 (71%)]	Loss: 1.464289
Train Epoch: 1 [38400/53386 (72%)]	Loss: 1.386757
Train Epoch: 1 [39040/53386 (73%)]	Loss: 1.341142
Train Epoch: 1 [39680/53386 (74%)]	Loss: 1.409653
Train Epoch: 1 [40320/53386 (76%)]	Loss: 1.350919
Train Epoch: 1 [40960/53386 (77%)]	Loss: 1.349938
Train Epoch: 1 [41600/53386 (78%)]	Loss: 1.434787
Train Epoch: 1 [42240/53386 (79%)]	Loss: 1.372691
Train Epoch: 1 [42880/53386 (80%)]	Loss: 1.384659
Train Epoch: 1 [43520/53386 (82%)]	Loss: 1.370581
Train Epoch: 1 [44160/53386 (83%)]	Loss: 1.357866
Train Epoch: 1 [44800/53386 (84%)]	Loss: 1.406830
Train Epoch: 1 [45440/53386 (85%)]	Loss: 1.395637
Train Epoch: 1 [46080/53386 (86%)]	Loss: 1.347493
Train Epoch: 1 [46720/53386 (88%)]	Loss: 1.425523
Train Epoch: 1 [47360/53386 (89%)]	Loss: 1.380895
Train Epoch: 1 [48000/53386 (90%)]	Loss: 1.406159
Train Epoch: 1 [48640/53386 (91%)]	Loss: 1.356342
Train Epoch: 1 [49280/53386 (92%)]	Loss: 1.434670
Train Epoch: 1 [49920/53386 (94%)]	Loss: 1.415940
Train Epoch: 1 [50560/53386 (95%)]	Loss: 1.299288
Train Epoch: 1 [51200/53386 (96%)]	Loss: 1.354706
Train Epoch: 1 [51840/53386 (97%)]	Loss: 1.400795
Train Epoch: 1 [52480/53386 (98%)]	Loss: 1.354124
Train Epoch: 1 [53120/53386 (100%)]	Loss: 1.270743
0.20305861621165164
0.19744628529081953
[[ 647  107   60    8    0   12    0 1579]
 [  42  143   36    1    0    2    0  877]
 [  96   17  937    7    0    2    0 2281]
 [  52    8   95   18    0    1    0  555]
 [  28   12   17    0    0    1    0  224]
 [ 119   21   28    6    0   13    0  299]
 [ 314   36   50    6    0    6    0  911]
 [ 245   65  277    5    0    6    0 5069]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.20305861621165164
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 2 [640/53386 (1%)]	Loss: 1.484135
Train Epoch: 2 [1280/53386 (2%)]	Loss: 1.335350
Train Epoch: 2 [1920/53386 (4%)]	Loss: 1.317649
Train Epoch: 2 [2560/53386 (5%)]	Loss: 1.340856
Train Epoch: 2 [3200/53386 (6%)]	Loss: 1.257069
Train Epoch: 2 [3840/53386 (7%)]	Loss: 1.351473
Train Epoch: 2 [4480/53386 (8%)]	Loss: 1.334082
Train Epoch: 2 [5120/53386 (10%)]	Loss: 1.317062
Train Epoch: 2 [5760/53386 (11%)]	Loss: 1.267827
Train Epoch: 2 [6400/53386 (12%)]	Loss: 1.372875
Train Epoch: 2 [7040/53386 (13%)]	Loss: 1.366121
Train Epoch: 2 [7680/53386 (14%)]	Loss: 1.308069
Train Epoch: 2 [8320/53386 (16%)]	Loss: 1.364626
Train Epoch: 2 [8960/53386 (17%)]	Loss: 1.288960
Train Epoch: 2 [9600/53386 (18%)]	Loss: 1.328783
Train Epoch: 2 [10240/53386 (19%)]	Loss: 1.304049
Train Epoch: 2 [10880/53386 (20%)]	Loss: 1.282798
Train Epoch: 2 [11520/53386 (22%)]	Loss: 1.282570
Train Epoch: 2 [12160/53386 (23%)]	Loss: 1.355121
Train Epoch: 2 [12800/53386 (24%)]	Loss: 1.347640
Train Epoch: 2 [13440/53386 (25%)]	Loss: 1.311834
Train Epoch: 2 [14080/53386 (26%)]	Loss: 1.314807
Train Epoch: 2 [14720/53386 (28%)]	Loss: 1.322111
Train Epoch: 2 [15360/53386 (29%)]	Loss: 1.344542
Train Epoch: 2 [16000/53386 (30%)]	Loss: 1.342246
Train Epoch: 2 [16640/53386 (31%)]	Loss: 1.309701
Train Epoch: 2 [17280/53386 (32%)]	Loss: 1.305772
Train Epoch: 2 [17920/53386 (34%)]	Loss: 1.368117
Train Epoch: 2 [18560/53386 (35%)]	Loss: 1.334717
Train Epoch: 2 [19200/53386 (36%)]	Loss: 1.271032
Train Epoch: 2 [19840/53386 (37%)]	Loss: 1.357638
Train Epoch: 2 [20480/53386 (38%)]	Loss: 1.331374
Train Epoch: 2 [21120/53386 (40%)]	Loss: 1.385255
Train Epoch: 2 [21760/53386 (41%)]	Loss: 1.347559
Train Epoch: 2 [22400/53386 (42%)]	Loss: 1.405259
Train Epoch: 2 [23040/53386 (43%)]	Loss: 1.301902
Train Epoch: 2 [23680/53386 (44%)]	Loss: 1.379528
Train Epoch: 2 [24320/53386 (46%)]	Loss: 1.397693
Train Epoch: 2 [24960/53386 (47%)]	Loss: 1.343993
Train Epoch: 2 [25600/53386 (48%)]	Loss: 1.314640
Train Epoch: 2 [26240/53386 (49%)]	Loss: 1.360094
Train Epoch: 2 [26880/53386 (50%)]	Loss: 1.309851
Train Epoch: 2 [27520/53386 (52%)]	Loss: 1.303753
Train Epoch: 2 [28160/53386 (53%)]	Loss: 1.321884
Train Epoch: 2 [28800/53386 (54%)]	Loss: 1.333828
Train Epoch: 2 [29440/53386 (55%)]	Loss: 1.316718
Train Epoch: 2 [30080/53386 (56%)]	Loss: 1.394045
Train Epoch: 2 [30720/53386 (58%)]	Loss: 1.358770
Train Epoch: 2 [31360/53386 (59%)]	Loss: 1.358328
Train Epoch: 2 [32000/53386 (60%)]	Loss: 1.282847
Train Epoch: 2 [32640/53386 (61%)]	Loss: 1.421174
Train Epoch: 2 [33280/53386 (62%)]	Loss: 1.334358
Train Epoch: 2 [33920/53386 (64%)]	Loss: 1.262715
Train Epoch: 2 [34560/53386 (65%)]	Loss: 1.306652
Train Epoch: 2 [35200/53386 (66%)]	Loss: 1.221239
Train Epoch: 2 [35840/53386 (67%)]	Loss: 1.392410
Train Epoch: 2 [36480/53386 (68%)]	Loss: 1.303473
Train Epoch: 2 [37120/53386 (70%)]	Loss: 1.406763
Train Epoch: 2 [37760/53386 (71%)]	Loss: 1.368058
Train Epoch: 2 [38400/53386 (72%)]	Loss: 1.364536
Train Epoch: 2 [39040/53386 (73%)]	Loss: 1.380348
Train Epoch: 2 [39680/53386 (74%)]	Loss: 1.266503
Train Epoch: 2 [40320/53386 (76%)]	Loss: 1.302053
Train Epoch: 2 [40960/53386 (77%)]	Loss: 1.279608
Train Epoch: 2 [41600/53386 (78%)]	Loss: 1.310134
Train Epoch: 2 [42240/53386 (79%)]	Loss: 1.291459
Train Epoch: 2 [42880/53386 (80%)]	Loss: 1.303643
Train Epoch: 2 [43520/53386 (82%)]	Loss: 1.261672
Train Epoch: 2 [44160/53386 (83%)]	Loss: 1.366027
Train Epoch: 2 [44800/53386 (84%)]	Loss: 1.326415
Train Epoch: 2 [45440/53386 (85%)]	Loss: 1.338366
Train Epoch: 2 [46080/53386 (86%)]	Loss: 1.285456
Train Epoch: 2 [46720/53386 (88%)]	Loss: 1.299596
Train Epoch: 2 [47360/53386 (89%)]	Loss: 1.246486
Train Epoch: 2 [48000/53386 (90%)]	Loss: 1.391789
Train Epoch: 2 [48640/53386 (91%)]	Loss: 1.326568
Train Epoch: 2 [49280/53386 (92%)]	Loss: 1.312443
Train Epoch: 2 [49920/53386 (94%)]	Loss: 1.371407
Train Epoch: 2 [50560/53386 (95%)]	Loss: 1.303046
Train Epoch: 2 [51200/53386 (96%)]	Loss: 1.363726
Train Epoch: 2 [51840/53386 (97%)]	Loss: 1.322235
Train Epoch: 2 [52480/53386 (98%)]	Loss: 1.324151
Train Epoch: 2 [53120/53386 (100%)]	Loss: 1.346322
0.251455029812609
0.25532307832818424
[[ 846  188  113   13    2   12   26 1213]
 [  78  359   44    7    4    0    2  607]
 [ 105   56 1154   39    3    8    5 1970]
 [  56   29  108   65    0    7    2  462]
 [  39   27   19    5    5    1    2  184]
 [ 136   46   27   12    0   24    6  235]
 [ 399   79   79    8    0   10   20  728]
 [ 342  227  398   26    5    7   26 4636]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.251455029812609
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 3 [640/53386 (1%)]	Loss: 1.336319
Train Epoch: 3 [1280/53386 (2%)]	Loss: 1.219585
Train Epoch: 3 [1920/53386 (4%)]	Loss: 1.196750
Train Epoch: 3 [2560/53386 (5%)]	Loss: 1.254431
Train Epoch: 3 [3200/53386 (6%)]	Loss: 1.276315
Train Epoch: 3 [3840/53386 (7%)]	Loss: 1.272077
Train Epoch: 3 [4480/53386 (8%)]	Loss: 1.270330
Train Epoch: 3 [5120/53386 (10%)]	Loss: 1.271786
Train Epoch: 3 [5760/53386 (11%)]	Loss: 1.278051
Train Epoch: 3 [6400/53386 (12%)]	Loss: 1.217910
Train Epoch: 3 [7040/53386 (13%)]	Loss: 1.258990
Train Epoch: 3 [7680/53386 (14%)]	Loss: 1.322198
Train Epoch: 3 [8320/53386 (16%)]	Loss: 1.286691
Train Epoch: 3 [8960/53386 (17%)]	Loss: 1.220976
Train Epoch: 3 [9600/53386 (18%)]	Loss: 1.291704
Train Epoch: 3 [10240/53386 (19%)]	Loss: 1.240418
Train Epoch: 3 [10880/53386 (20%)]	Loss: 1.222458
Train Epoch: 3 [11520/53386 (22%)]	Loss: 1.300790
Train Epoch: 3 [12160/53386 (23%)]	Loss: 1.210856
Train Epoch: 3 [12800/53386 (24%)]	Loss: 1.260263
Train Epoch: 3 [13440/53386 (25%)]	Loss: 1.321331
Train Epoch: 3 [14080/53386 (26%)]	Loss: 1.207640
Train Epoch: 3 [14720/53386 (28%)]	Loss: 1.232358
Train Epoch: 3 [15360/53386 (29%)]	Loss: 1.263306
Train Epoch: 3 [16000/53386 (30%)]	Loss: 1.187097
Train Epoch: 3 [16640/53386 (31%)]	Loss: 1.245653
Train Epoch: 3 [17280/53386 (32%)]	Loss: 1.287784
Train Epoch: 3 [17920/53386 (34%)]	Loss: 1.257791
Train Epoch: 3 [18560/53386 (35%)]	Loss: 1.224313
Train Epoch: 3 [19200/53386 (36%)]	Loss: 1.209164
Train Epoch: 3 [19840/53386 (37%)]	Loss: 1.265390
Train Epoch: 3 [20480/53386 (38%)]	Loss: 1.209292
Train Epoch: 3 [21120/53386 (40%)]	Loss: 1.273154
Train Epoch: 3 [21760/53386 (41%)]	Loss: 1.265141
Train Epoch: 3 [22400/53386 (42%)]	Loss: 1.242819
Train Epoch: 3 [23040/53386 (43%)]	Loss: 1.207893
Train Epoch: 3 [23680/53386 (44%)]	Loss: 1.331859
Train Epoch: 3 [24320/53386 (46%)]	Loss: 1.264556
Train Epoch: 3 [24960/53386 (47%)]	Loss: 1.294312
Train Epoch: 3 [25600/53386 (48%)]	Loss: 1.231507
Train Epoch: 3 [26240/53386 (49%)]	Loss: 1.265034
Train Epoch: 3 [26880/53386 (50%)]	Loss: 1.243071
Train Epoch: 3 [27520/53386 (52%)]	Loss: 1.260370
Train Epoch: 3 [28160/53386 (53%)]	Loss: 1.246336
Train Epoch: 3 [28800/53386 (54%)]	Loss: 1.270176
Train Epoch: 3 [29440/53386 (55%)]	Loss: 1.243666
Train Epoch: 3 [30080/53386 (56%)]	Loss: 1.277319
Train Epoch: 3 [30720/53386 (58%)]	Loss: 1.196450
Train Epoch: 3 [31360/53386 (59%)]	Loss: 1.226032
Train Epoch: 3 [32000/53386 (60%)]	Loss: 1.244124
Train Epoch: 3 [32640/53386 (61%)]	Loss: 1.260044
Train Epoch: 3 [33280/53386 (62%)]	Loss: 1.219219
Train Epoch: 3 [33920/53386 (64%)]	Loss: 1.154263
Train Epoch: 3 [34560/53386 (65%)]	Loss: 1.324552
Train Epoch: 3 [35200/53386 (66%)]	Loss: 1.263709
Train Epoch: 3 [35840/53386 (67%)]	Loss: 1.215077
Train Epoch: 3 [36480/53386 (68%)]	Loss: 1.357034
Train Epoch: 3 [37120/53386 (70%)]	Loss: 1.284865
Train Epoch: 3 [37760/53386 (71%)]	Loss: 1.298009
Train Epoch: 3 [38400/53386 (72%)]	Loss: 1.265165
Train Epoch: 3 [39040/53386 (73%)]	Loss: 1.249439
Train Epoch: 3 [39680/53386 (74%)]	Loss: 1.235069
Train Epoch: 3 [40320/53386 (76%)]	Loss: 1.245733
Train Epoch: 3 [40960/53386 (77%)]	Loss: 1.218548
Train Epoch: 3 [41600/53386 (78%)]	Loss: 1.244530
Train Epoch: 3 [42240/53386 (79%)]	Loss: 1.265476
Train Epoch: 3 [42880/53386 (80%)]	Loss: 1.245234
Train Epoch: 3 [43520/53386 (82%)]	Loss: 1.246490
Train Epoch: 3 [44160/53386 (83%)]	Loss: 1.287533
Train Epoch: 3 [44800/53386 (84%)]	Loss: 1.249310
Train Epoch: 3 [45440/53386 (85%)]	Loss: 1.241975
Train Epoch: 3 [46080/53386 (86%)]	Loss: 1.243581
Train Epoch: 3 [46720/53386 (88%)]	Loss: 1.303726
Train Epoch: 3 [47360/53386 (89%)]	Loss: 1.227353
Train Epoch: 3 [48000/53386 (90%)]	Loss: 1.263659
Train Epoch: 3 [48640/53386 (91%)]	Loss: 1.286611
Train Epoch: 3 [49280/53386 (92%)]	Loss: 1.251497
Train Epoch: 3 [49920/53386 (94%)]	Loss: 1.226190
Train Epoch: 3 [50560/53386 (95%)]	Loss: 1.277515
Train Epoch: 3 [51200/53386 (96%)]	Loss: 1.271236
Train Epoch: 3 [51840/53386 (97%)]	Loss: 1.282570
Train Epoch: 3 [52480/53386 (98%)]	Loss: 1.205124
Train Epoch: 3 [53120/53386 (100%)]	Loss: 1.197440
0.267039197627551
0.2823116079832082
[[ 665  114  107   21   11  139  166 1190]
 [  51  306   47    6   15   15   18  643]
 [ 109   55 1262   48    7   24   45 1790]
 [  43   30  106   73    1   20   20  436]
 [  30   12   22    6   10    5   19  178]
 [  65   21   18   12    1   84   48  237]
 [ 254   42   79   13    2   88  143  702]
 [ 249  160  517   47   17   66  143 4468]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.267039197627551
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 4 [640/53386 (1%)]	Loss: 1.297695
Train Epoch: 4 [1280/53386 (2%)]	Loss: 1.239349
Train Epoch: 4 [1920/53386 (4%)]	Loss: 1.110927
Train Epoch: 4 [2560/53386 (5%)]	Loss: 1.179380
Train Epoch: 4 [3200/53386 (6%)]	Loss: 1.134190
Train Epoch: 4 [3840/53386 (7%)]	Loss: 1.218275
Train Epoch: 4 [4480/53386 (8%)]	Loss: 1.136589
Train Epoch: 4 [5120/53386 (10%)]	Loss: 1.139439
Train Epoch: 4 [5760/53386 (11%)]	Loss: 1.095558
Train Epoch: 4 [6400/53386 (12%)]	Loss: 1.202100
Train Epoch: 4 [7040/53386 (13%)]	Loss: 1.138972
Train Epoch: 4 [7680/53386 (14%)]	Loss: 1.154190
Train Epoch: 4 [8320/53386 (16%)]	Loss: 1.190080
Train Epoch: 4 [8960/53386 (17%)]	Loss: 1.204685
Train Epoch: 4 [9600/53386 (18%)]	Loss: 1.161736
Train Epoch: 4 [10240/53386 (19%)]	Loss: 1.137670
Train Epoch: 4 [10880/53386 (20%)]	Loss: 1.146266
Train Epoch: 4 [11520/53386 (22%)]	Loss: 1.113803
Train Epoch: 4 [12160/53386 (23%)]	Loss: 1.165009
Train Epoch: 4 [12800/53386 (24%)]	Loss: 1.161290
Train Epoch: 4 [13440/53386 (25%)]	Loss: 1.152493
Train Epoch: 4 [14080/53386 (26%)]	Loss: 1.178836
Train Epoch: 4 [14720/53386 (28%)]	Loss: 1.160813
Train Epoch: 4 [15360/53386 (29%)]	Loss: 1.175782
Train Epoch: 4 [16000/53386 (30%)]	Loss: 1.155037
Train Epoch: 4 [16640/53386 (31%)]	Loss: 1.099818
Train Epoch: 4 [17280/53386 (32%)]	Loss: 1.108557
Train Epoch: 4 [17920/53386 (34%)]	Loss: 1.196292
Train Epoch: 4 [18560/53386 (35%)]	Loss: 1.185119
Train Epoch: 4 [19200/53386 (36%)]	Loss: 1.145374
Train Epoch: 4 [19840/53386 (37%)]	Loss: 1.175811
Train Epoch: 4 [20480/53386 (38%)]	Loss: 1.172592
Train Epoch: 4 [21120/53386 (40%)]	Loss: 1.141185
Train Epoch: 4 [21760/53386 (41%)]	Loss: 1.170608
Train Epoch: 4 [22400/53386 (42%)]	Loss: 1.194956
Train Epoch: 4 [23040/53386 (43%)]	Loss: 1.102436
Train Epoch: 4 [23680/53386 (44%)]	Loss: 1.210218
Train Epoch: 4 [24320/53386 (46%)]	Loss: 1.200000
Train Epoch: 4 [24960/53386 (47%)]	Loss: 1.148538
Train Epoch: 4 [25600/53386 (48%)]	Loss: 1.088920
Train Epoch: 4 [26240/53386 (49%)]	Loss: 1.085862
Train Epoch: 4 [26880/53386 (50%)]	Loss: 1.080975
Train Epoch: 4 [27520/53386 (52%)]	Loss: 1.145970
Train Epoch: 4 [28160/53386 (53%)]	Loss: 1.116371
Train Epoch: 4 [28800/53386 (54%)]	Loss: 1.160049
Train Epoch: 4 [29440/53386 (55%)]	Loss: 1.231729
Train Epoch: 4 [30080/53386 (56%)]	Loss: 1.203735
Train Epoch: 4 [30720/53386 (58%)]	Loss: 1.216254
Train Epoch: 4 [31360/53386 (59%)]	Loss: 1.154565
Train Epoch: 4 [32000/53386 (60%)]	Loss: 1.201756
Train Epoch: 4 [32640/53386 (61%)]	Loss: 1.170569
Train Epoch: 4 [33280/53386 (62%)]	Loss: 1.115155
Train Epoch: 4 [33920/53386 (64%)]	Loss: 1.221572
Train Epoch: 4 [34560/53386 (65%)]	Loss: 1.128161
Train Epoch: 4 [35200/53386 (66%)]	Loss: 1.133008
Train Epoch: 4 [35840/53386 (67%)]	Loss: 1.212405
Train Epoch: 4 [36480/53386 (68%)]	Loss: 1.128939
Train Epoch: 4 [37120/53386 (70%)]	Loss: 1.180830
Train Epoch: 4 [37760/53386 (71%)]	Loss: 1.187864
Train Epoch: 4 [38400/53386 (72%)]	Loss: 1.167670
Train Epoch: 4 [39040/53386 (73%)]	Loss: 1.159289
Train Epoch: 4 [39680/53386 (74%)]	Loss: 1.078431
Train Epoch: 4 [40320/53386 (76%)]	Loss: 1.187888
Train Epoch: 4 [40960/53386 (77%)]	Loss: 1.178889
Train Epoch: 4 [41600/53386 (78%)]	Loss: 1.204144
Train Epoch: 4 [42240/53386 (79%)]	Loss: 1.098391
Train Epoch: 4 [42880/53386 (80%)]	Loss: 1.184599
Train Epoch: 4 [43520/53386 (82%)]	Loss: 1.157148
Train Epoch: 4 [44160/53386 (83%)]	Loss: 1.132572
Train Epoch: 4 [44800/53386 (84%)]	Loss: 1.142693
Train Epoch: 4 [45440/53386 (85%)]	Loss: 1.200927
Train Epoch: 4 [46080/53386 (86%)]	Loss: 1.149242
Train Epoch: 4 [46720/53386 (88%)]	Loss: 1.129418
Train Epoch: 4 [47360/53386 (89%)]	Loss: 1.194562
Train Epoch: 4 [48000/53386 (90%)]	Loss: 1.128590
Train Epoch: 4 [48640/53386 (91%)]	Loss: 1.157944
Train Epoch: 4 [49280/53386 (92%)]	Loss: 1.190221
Train Epoch: 4 [49920/53386 (94%)]	Loss: 1.180794
Train Epoch: 4 [50560/53386 (95%)]	Loss: 1.180704
Train Epoch: 4 [51200/53386 (96%)]	Loss: 1.056529
Train Epoch: 4 [51840/53386 (97%)]	Loss: 1.179968
Train Epoch: 4 [52480/53386 (98%)]	Loss: 1.182669
Train Epoch: 4 [53120/53386 (100%)]	Loss: 1.125268
0.2866970023244225
0.2890966610217065
[[ 940  208  195   37   16  130   48  839]
 [  75  374   84   16   16   16    8  512]
 [ 162   88 1522   91    9   27   14 1427]
 [  65   41  140  106    3   18    9  347]
 [  51   25   36    9   14    6    4  137]
 [ 130   42   39   17    2   96   17  143]
 [ 422   91  137   20    3   97   42  511]
 [ 478  290  773   86   23   80   59 3878]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.2866970023244225
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 5 [640/53386 (1%)]	Loss: 1.223375
Train Epoch: 5 [1280/53386 (2%)]	Loss: 1.044023
Train Epoch: 5 [1920/53386 (4%)]	Loss: 1.083539
Train Epoch: 5 [2560/53386 (5%)]	Loss: 1.021961
Train Epoch: 5 [3200/53386 (6%)]	Loss: 1.080273
Train Epoch: 5 [3840/53386 (7%)]	Loss: 0.977183
Train Epoch: 5 [4480/53386 (8%)]	Loss: 1.011820
Train Epoch: 5 [5120/53386 (10%)]	Loss: 1.002862
Train Epoch: 5 [5760/53386 (11%)]	Loss: 1.021310
Train Epoch: 5 [6400/53386 (12%)]	Loss: 1.035327
Train Epoch: 5 [7040/53386 (13%)]	Loss: 0.960464
Train Epoch: 5 [7680/53386 (14%)]	Loss: 1.036880
Train Epoch: 5 [8320/53386 (16%)]	Loss: 1.031300
Train Epoch: 5 [8960/53386 (17%)]	Loss: 1.069139
Train Epoch: 5 [9600/53386 (18%)]	Loss: 1.023150
Train Epoch: 5 [10240/53386 (19%)]	Loss: 1.040432
Train Epoch: 5 [10880/53386 (20%)]	Loss: 1.054434
Train Epoch: 5 [11520/53386 (22%)]	Loss: 1.065124
Train Epoch: 5 [12160/53386 (23%)]	Loss: 1.034132
Train Epoch: 5 [12800/53386 (24%)]	Loss: 1.054157
Train Epoch: 5 [13440/53386 (25%)]	Loss: 1.020126
Train Epoch: 5 [14080/53386 (26%)]	Loss: 0.999026
Train Epoch: 5 [14720/53386 (28%)]	Loss: 0.953790
Train Epoch: 5 [15360/53386 (29%)]	Loss: 1.059200
Train Epoch: 5 [16000/53386 (30%)]	Loss: 1.036730
Train Epoch: 5 [16640/53386 (31%)]	Loss: 1.117256
Train Epoch: 5 [17280/53386 (32%)]	Loss: 0.999461
Train Epoch: 5 [17920/53386 (34%)]	Loss: 1.084128
Train Epoch: 5 [18560/53386 (35%)]	Loss: 1.067372
Train Epoch: 5 [19200/53386 (36%)]	Loss: 1.090783
Train Epoch: 5 [19840/53386 (37%)]	Loss: 1.022945
Train Epoch: 5 [20480/53386 (38%)]	Loss: 1.020172
Train Epoch: 5 [21120/53386 (40%)]	Loss: 1.037039
Train Epoch: 5 [21760/53386 (41%)]	Loss: 1.037454
Train Epoch: 5 [22400/53386 (42%)]	Loss: 0.917564
Train Epoch: 5 [23040/53386 (43%)]	Loss: 0.991787
Train Epoch: 5 [23680/53386 (44%)]	Loss: 1.056816
Train Epoch: 5 [24320/53386 (46%)]	Loss: 1.076423
Train Epoch: 5 [24960/53386 (47%)]	Loss: 1.028790
Train Epoch: 5 [25600/53386 (48%)]	Loss: 1.013721
Train Epoch: 5 [26240/53386 (49%)]	Loss: 0.997482
Train Epoch: 5 [26880/53386 (50%)]	Loss: 1.094264
Train Epoch: 5 [27520/53386 (52%)]	Loss: 1.031255
Train Epoch: 5 [28160/53386 (53%)]	Loss: 1.052037
Train Epoch: 5 [28800/53386 (54%)]	Loss: 0.983191
Train Epoch: 5 [29440/53386 (55%)]	Loss: 1.003644
Train Epoch: 5 [30080/53386 (56%)]	Loss: 0.999564
Train Epoch: 5 [30720/53386 (58%)]	Loss: 1.118267
Train Epoch: 5 [31360/53386 (59%)]	Loss: 0.928633
Train Epoch: 5 [32000/53386 (60%)]	Loss: 1.045152
Train Epoch: 5 [32640/53386 (61%)]	Loss: 1.064441
Train Epoch: 5 [33280/53386 (62%)]	Loss: 1.031727
Train Epoch: 5 [33920/53386 (64%)]	Loss: 1.037177
Train Epoch: 5 [34560/53386 (65%)]	Loss: 1.069944
Train Epoch: 5 [35200/53386 (66%)]	Loss: 1.024564
Train Epoch: 5 [35840/53386 (67%)]	Loss: 1.021221
Train Epoch: 5 [36480/53386 (68%)]	Loss: 1.051425
Train Epoch: 5 [37120/53386 (70%)]	Loss: 0.967172
Train Epoch: 5 [37760/53386 (71%)]	Loss: 1.022380
Train Epoch: 5 [38400/53386 (72%)]	Loss: 1.096307
Train Epoch: 5 [39040/53386 (73%)]	Loss: 1.027621
Train Epoch: 5 [39680/53386 (74%)]	Loss: 1.037926
Train Epoch: 5 [40320/53386 (76%)]	Loss: 1.075141
Train Epoch: 5 [40960/53386 (77%)]	Loss: 1.007338
Train Epoch: 5 [41600/53386 (78%)]	Loss: 1.034052
Train Epoch: 5 [42240/53386 (79%)]	Loss: 1.000999
Train Epoch: 5 [42880/53386 (80%)]	Loss: 1.040990
Train Epoch: 5 [43520/53386 (82%)]	Loss: 1.012407
Train Epoch: 5 [44160/53386 (83%)]	Loss: 1.065068
Train Epoch: 5 [44800/53386 (84%)]	Loss: 1.006387
Train Epoch: 5 [45440/53386 (85%)]	Loss: 1.081108
Train Epoch: 5 [46080/53386 (86%)]	Loss: 1.071234
Train Epoch: 5 [46720/53386 (88%)]	Loss: 0.987229
Train Epoch: 5 [47360/53386 (89%)]	Loss: 1.042000
Train Epoch: 5 [48000/53386 (90%)]	Loss: 1.016229
Train Epoch: 5 [48640/53386 (91%)]	Loss: 0.956917
Train Epoch: 5 [49280/53386 (92%)]	Loss: 1.125398
Train Epoch: 5 [49920/53386 (94%)]	Loss: 1.091374
Train Epoch: 5 [50560/53386 (95%)]	Loss: 1.049157
Train Epoch: 5 [51200/53386 (96%)]	Loss: 1.081518
Train Epoch: 5 [51840/53386 (97%)]	Loss: 1.050248
Train Epoch: 5 [52480/53386 (98%)]	Loss: 1.054264
Train Epoch: 5 [53120/53386 (100%)]	Loss: 1.015195
0.277597022113204
0.2733780671787475
[[ 556  261  163   43   21  270  113  986]
 [  41  438   60   15   15   22   10  500]
 [  79  122 1289   91   14   55   26 1664]
 [  28   67  108   90    5   43   11  377]
 [  26   31   30    7   18   17    4  149]
 [  50   60   27   13    6  120   26  184]
 [ 206  136  103   22    7  190   82  577]
 [ 235  411  633   74   30  158  100 4026]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.2866970023244225
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 6 [640/53386 (1%)]	Loss: 1.003548
Train Epoch: 6 [1280/53386 (2%)]	Loss: 0.928185
Train Epoch: 6 [1920/53386 (4%)]	Loss: 0.887814
Train Epoch: 6 [2560/53386 (5%)]	Loss: 0.884703
Train Epoch: 6 [3200/53386 (6%)]	Loss: 0.861772
Train Epoch: 6 [3840/53386 (7%)]	Loss: 0.899186
Train Epoch: 6 [4480/53386 (8%)]	Loss: 0.872211
Train Epoch: 6 [5120/53386 (10%)]	Loss: 0.923454
Train Epoch: 6 [5760/53386 (11%)]	Loss: 0.952700
Train Epoch: 6 [6400/53386 (12%)]	Loss: 0.941634
Train Epoch: 6 [7040/53386 (13%)]	Loss: 0.888466
Train Epoch: 6 [7680/53386 (14%)]	Loss: 0.895291
Train Epoch: 6 [8320/53386 (16%)]	Loss: 0.887303
Train Epoch: 6 [8960/53386 (17%)]	Loss: 0.811532
Train Epoch: 6 [9600/53386 (18%)]	Loss: 0.927038
Train Epoch: 6 [10240/53386 (19%)]	Loss: 0.891719
Train Epoch: 6 [10880/53386 (20%)]	Loss: 0.841626
Train Epoch: 6 [11520/53386 (22%)]	Loss: 0.848883
Train Epoch: 6 [12160/53386 (23%)]	Loss: 0.915185
Train Epoch: 6 [12800/53386 (24%)]	Loss: 0.883840
Train Epoch: 6 [13440/53386 (25%)]	Loss: 0.891945
Train Epoch: 6 [14080/53386 (26%)]	Loss: 0.880588
Train Epoch: 6 [14720/53386 (28%)]	Loss: 0.896101
Train Epoch: 6 [15360/53386 (29%)]	Loss: 0.948045
Train Epoch: 6 [16000/53386 (30%)]	Loss: 0.997742
Train Epoch: 6 [16640/53386 (31%)]	Loss: 0.936799
Train Epoch: 6 [17280/53386 (32%)]	Loss: 0.906548
Train Epoch: 6 [17920/53386 (34%)]	Loss: 0.971672
Train Epoch: 6 [18560/53386 (35%)]	Loss: 0.952644
Train Epoch: 6 [19200/53386 (36%)]	Loss: 0.921773
Train Epoch: 6 [19840/53386 (37%)]	Loss: 0.889040
Train Epoch: 6 [20480/53386 (38%)]	Loss: 0.902878
Train Epoch: 6 [21120/53386 (40%)]	Loss: 0.919263
Train Epoch: 6 [21760/53386 (41%)]	Loss: 0.828242
Train Epoch: 6 [22400/53386 (42%)]	Loss: 0.884206
Train Epoch: 6 [23040/53386 (43%)]	Loss: 0.889534
Train Epoch: 6 [23680/53386 (44%)]	Loss: 0.908240
Train Epoch: 6 [24320/53386 (46%)]	Loss: 0.954538
Train Epoch: 6 [24960/53386 (47%)]	Loss: 0.875953
Train Epoch: 6 [25600/53386 (48%)]	Loss: 0.898331
Train Epoch: 6 [26240/53386 (49%)]	Loss: 0.895357
Train Epoch: 6 [26880/53386 (50%)]	Loss: 0.935603
Train Epoch: 6 [27520/53386 (52%)]	Loss: 0.892299
Train Epoch: 6 [28160/53386 (53%)]	Loss: 0.990787
Train Epoch: 6 [28800/53386 (54%)]	Loss: 0.945581
Train Epoch: 6 [29440/53386 (55%)]	Loss: 0.934195
Train Epoch: 6 [30080/53386 (56%)]	Loss: 0.907222
Train Epoch: 6 [30720/53386 (58%)]	Loss: 0.913557
Train Epoch: 6 [31360/53386 (59%)]	Loss: 0.873233
Train Epoch: 6 [32000/53386 (60%)]	Loss: 0.978244
Train Epoch: 6 [32640/53386 (61%)]	Loss: 0.927691
Train Epoch: 6 [33280/53386 (62%)]	Loss: 0.877130
Train Epoch: 6 [33920/53386 (64%)]	Loss: 0.892220
Train Epoch: 6 [34560/53386 (65%)]	Loss: 0.913334
Train Epoch: 6 [35200/53386 (66%)]	Loss: 0.938978
Train Epoch: 6 [35840/53386 (67%)]	Loss: 0.902106
Train Epoch: 6 [36480/53386 (68%)]	Loss: 0.902206
Train Epoch: 6 [37120/53386 (70%)]	Loss: 0.821286
Train Epoch: 6 [37760/53386 (71%)]	Loss: 0.892219
Train Epoch: 6 [38400/53386 (72%)]	Loss: 0.901984
Train Epoch: 6 [39040/53386 (73%)]	Loss: 0.893700
Train Epoch: 6 [39680/53386 (74%)]	Loss: 0.929678
Train Epoch: 6 [40320/53386 (76%)]	Loss: 0.991131
Train Epoch: 6 [40960/53386 (77%)]	Loss: 0.862652
Train Epoch: 6 [41600/53386 (78%)]	Loss: 0.945759
Train Epoch: 6 [42240/53386 (79%)]	Loss: 0.927081
Train Epoch: 6 [42880/53386 (80%)]	Loss: 0.936570
Train Epoch: 6 [43520/53386 (82%)]	Loss: 0.824459
Train Epoch: 6 [44160/53386 (83%)]	Loss: 0.893123
Train Epoch: 6 [44800/53386 (84%)]	Loss: 0.979413
Train Epoch: 6 [45440/53386 (85%)]	Loss: 0.958066
Train Epoch: 6 [46080/53386 (86%)]	Loss: 0.853730
Train Epoch: 6 [46720/53386 (88%)]	Loss: 0.927672
Train Epoch: 6 [47360/53386 (89%)]	Loss: 0.944422
Train Epoch: 6 [48000/53386 (90%)]	Loss: 0.960646
Train Epoch: 6 [48640/53386 (91%)]	Loss: 0.942697
Train Epoch: 6 [49280/53386 (92%)]	Loss: 0.913484
Train Epoch: 6 [49920/53386 (94%)]	Loss: 0.874118
Train Epoch: 6 [50560/53386 (95%)]	Loss: 0.987589
Train Epoch: 6 [51200/53386 (96%)]	Loss: 1.001624
Train Epoch: 6 [51840/53386 (97%)]	Loss: 0.887192
Train Epoch: 6 [52480/53386 (98%)]	Loss: 0.992388
Train Epoch: 6 [53120/53386 (100%)]	Loss: 0.975469
0.28634482708928044
0.2899514840262754
[[ 829  120  273   86   20  169  260  656]
 [  89  319  116   42   26   39   43  427]
 [ 155   91 1615  146   19   37   80 1197]
 [  59   37  175  130    6   25   35  262]
 [  40   17   49   13   18   15   19  111]
 [  95   24   49   23    6  104   64  121]
 [ 345   68  177   42    9  121  200  361]
 [ 429  249 1126  166   39  109  338 3211]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.2866970023244225
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 7 [640/53386 (1%)]	Loss: 0.780357
Train Epoch: 7 [1280/53386 (2%)]	Loss: 0.701795
Train Epoch: 7 [1920/53386 (4%)]	Loss: 0.754611
Train Epoch: 7 [2560/53386 (5%)]	Loss: 0.823525
Train Epoch: 7 [3200/53386 (6%)]	Loss: 0.713183
Train Epoch: 7 [3840/53386 (7%)]	Loss: 0.745487
Train Epoch: 7 [4480/53386 (8%)]	Loss: 0.820924
Train Epoch: 7 [5120/53386 (10%)]	Loss: 0.735504
Train Epoch: 7 [5760/53386 (11%)]	Loss: 0.764723
Train Epoch: 7 [6400/53386 (12%)]	Loss: 0.741525
Train Epoch: 7 [7040/53386 (13%)]	Loss: 0.770768
Train Epoch: 7 [7680/53386 (14%)]	Loss: 0.815400
Train Epoch: 7 [8320/53386 (16%)]	Loss: 0.784336
Train Epoch: 7 [8960/53386 (17%)]	Loss: 0.751212
Train Epoch: 7 [9600/53386 (18%)]	Loss: 0.711729
Train Epoch: 7 [10240/53386 (19%)]	Loss: 0.788660
Train Epoch: 7 [10880/53386 (20%)]	Loss: 0.685326
Train Epoch: 7 [11520/53386 (22%)]	Loss: 0.789349
Train Epoch: 7 [12160/53386 (23%)]	Loss: 0.787110
Train Epoch: 7 [12800/53386 (24%)]	Loss: 0.773273
Train Epoch: 7 [13440/53386 (25%)]	Loss: 0.781221
Train Epoch: 7 [14080/53386 (26%)]	Loss: 0.849956
Train Epoch: 7 [14720/53386 (28%)]	Loss: 0.844797
Train Epoch: 7 [15360/53386 (29%)]	Loss: 0.749149
Train Epoch: 7 [16000/53386 (30%)]	Loss: 0.768773
Train Epoch: 7 [16640/53386 (31%)]	Loss: 0.760404
Train Epoch: 7 [17280/53386 (32%)]	Loss: 0.744493
Train Epoch: 7 [17920/53386 (34%)]	Loss: 0.824212
Train Epoch: 7 [18560/53386 (35%)]	Loss: 0.688295
Train Epoch: 7 [19200/53386 (36%)]	Loss: 0.688445
Train Epoch: 7 [19840/53386 (37%)]	Loss: 0.788820
Train Epoch: 7 [20480/53386 (38%)]	Loss: 0.726186
Train Epoch: 7 [21120/53386 (40%)]	Loss: 0.816754
Train Epoch: 7 [21760/53386 (41%)]	Loss: 0.763367
Train Epoch: 7 [22400/53386 (42%)]	Loss: 0.780816
Train Epoch: 7 [23040/53386 (43%)]	Loss: 0.771357
Train Epoch: 7 [23680/53386 (44%)]	Loss: 0.819351
Train Epoch: 7 [24320/53386 (46%)]	Loss: 0.859342
Train Epoch: 7 [24960/53386 (47%)]	Loss: 0.756778
Train Epoch: 7 [25600/53386 (48%)]	Loss: 0.794549
Train Epoch: 7 [26240/53386 (49%)]	Loss: 0.836612
Train Epoch: 7 [26880/53386 (50%)]	Loss: 0.732694
Train Epoch: 7 [27520/53386 (52%)]	Loss: 0.728770
Train Epoch: 7 [28160/53386 (53%)]	Loss: 0.843536
Train Epoch: 7 [28800/53386 (54%)]	Loss: 0.805043
Train Epoch: 7 [29440/53386 (55%)]	Loss: 0.752501
Train Epoch: 7 [30080/53386 (56%)]	Loss: 0.780101
Train Epoch: 7 [30720/53386 (58%)]	Loss: 0.740661
Train Epoch: 7 [31360/53386 (59%)]	Loss: 0.768382
Train Epoch: 7 [32000/53386 (60%)]	Loss: 0.771009
Train Epoch: 7 [32640/53386 (61%)]	Loss: 0.733164
Train Epoch: 7 [33280/53386 (62%)]	Loss: 0.693151
Train Epoch: 7 [33920/53386 (64%)]	Loss: 0.791992
Train Epoch: 7 [34560/53386 (65%)]	Loss: 0.780560
Train Epoch: 7 [35200/53386 (66%)]	Loss: 0.796062
Train Epoch: 7 [35840/53386 (67%)]	Loss: 0.834011
Train Epoch: 7 [36480/53386 (68%)]	Loss: 0.728204
Train Epoch: 7 [37120/53386 (70%)]	Loss: 0.729199
Train Epoch: 7 [37760/53386 (71%)]	Loss: 0.814562
Train Epoch: 7 [38400/53386 (72%)]	Loss: 0.764013
Train Epoch: 7 [39040/53386 (73%)]	Loss: 0.713474
Train Epoch: 7 [39680/53386 (74%)]	Loss: 0.752204
Train Epoch: 7 [40320/53386 (76%)]	Loss: 0.743168
Train Epoch: 7 [40960/53386 (77%)]	Loss: 0.824187
Train Epoch: 7 [41600/53386 (78%)]	Loss: 0.772567
Train Epoch: 7 [42240/53386 (79%)]	Loss: 0.782707
Train Epoch: 7 [42880/53386 (80%)]	Loss: 0.777773
Train Epoch: 7 [43520/53386 (82%)]	Loss: 0.815109
Train Epoch: 7 [44160/53386 (83%)]	Loss: 0.774562
Train Epoch: 7 [44800/53386 (84%)]	Loss: 0.726468
Train Epoch: 7 [45440/53386 (85%)]	Loss: 0.837411
Train Epoch: 7 [46080/53386 (86%)]	Loss: 0.777970
Train Epoch: 7 [46720/53386 (88%)]	Loss: 0.723229
Train Epoch: 7 [47360/53386 (89%)]	Loss: 0.810089
Train Epoch: 7 [48000/53386 (90%)]	Loss: 0.768686
Train Epoch: 7 [48640/53386 (91%)]	Loss: 0.778798
Train Epoch: 7 [49280/53386 (92%)]	Loss: 0.695410
Train Epoch: 7 [49920/53386 (94%)]	Loss: 0.752642
Train Epoch: 7 [50560/53386 (95%)]	Loss: 0.765800
Train Epoch: 7 [51200/53386 (96%)]	Loss: 0.765307
Train Epoch: 7 [51840/53386 (97%)]	Loss: 0.789831
Train Epoch: 7 [52480/53386 (98%)]	Loss: 0.762318
Train Epoch: 7 [53120/53386 (100%)]	Loss: 0.776823
0.2623006695586609
0.27158505612877365
[[ 657  142  214   54   18  142  233  953]
 [  52  300   76   25   20   14   43  571]
 [ 113   70 1398  109    7   29   75 1539]
 [  43   39  146   90    5   27   30  349]
 [  33   18   41   11   12   10   11  146]
 [  68   39   38   15    6   82   66  172]
 [ 239   78  134   28    7  102  175  560]
 [ 315  223  883  121   27   83  229 3786]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.2866970023244225
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 8 [640/53386 (1%)]	Loss: 0.609232
Train Epoch: 8 [1280/53386 (2%)]	Loss: 0.603474
Train Epoch: 8 [1920/53386 (4%)]	Loss: 0.639346
Train Epoch: 8 [2560/53386 (5%)]	Loss: 0.631950
Train Epoch: 8 [3200/53386 (6%)]	Loss: 0.555219
Train Epoch: 8 [3840/53386 (7%)]	Loss: 0.582065
Train Epoch: 8 [4480/53386 (8%)]	Loss: 0.603989
Train Epoch: 8 [5120/53386 (10%)]	Loss: 0.630685
Train Epoch: 8 [5760/53386 (11%)]	Loss: 0.556023
Train Epoch: 8 [6400/53386 (12%)]	Loss: 0.641595
Train Epoch: 8 [7040/53386 (13%)]	Loss: 0.574540
Train Epoch: 8 [7680/53386 (14%)]	Loss: 0.717778
Train Epoch: 8 [8320/53386 (16%)]	Loss: 0.618129
Train Epoch: 8 [8960/53386 (17%)]	Loss: 0.648774
Train Epoch: 8 [9600/53386 (18%)]	Loss: 0.651603
Train Epoch: 8 [10240/53386 (19%)]	Loss: 0.640714
Train Epoch: 8 [10880/53386 (20%)]	Loss: 0.579049
Train Epoch: 8 [11520/53386 (22%)]	Loss: 0.636770
Train Epoch: 8 [12160/53386 (23%)]	Loss: 0.598836
Train Epoch: 8 [12800/53386 (24%)]	Loss: 0.618664
Train Epoch: 8 [13440/53386 (25%)]	Loss: 0.606467
Train Epoch: 8 [14080/53386 (26%)]	Loss: 0.627879
Train Epoch: 8 [14720/53386 (28%)]	Loss: 0.606746
Train Epoch: 8 [15360/53386 (29%)]	Loss: 0.651550
Train Epoch: 8 [16000/53386 (30%)]	Loss: 0.607409
Train Epoch: 8 [16640/53386 (31%)]	Loss: 0.554975
Train Epoch: 8 [17280/53386 (32%)]	Loss: 0.611639
Train Epoch: 8 [17920/53386 (34%)]	Loss: 0.606922
Train Epoch: 8 [18560/53386 (35%)]	Loss: 0.641424
Train Epoch: 8 [19200/53386 (36%)]	Loss: 0.626070
Train Epoch: 8 [19840/53386 (37%)]	Loss: 0.619209
Train Epoch: 8 [20480/53386 (38%)]	Loss: 0.653216
Train Epoch: 8 [21120/53386 (40%)]	Loss: 0.611293
Train Epoch: 8 [21760/53386 (41%)]	Loss: 0.641376
Train Epoch: 8 [22400/53386 (42%)]	Loss: 0.588079
Train Epoch: 8 [23040/53386 (43%)]	Loss: 0.653501
Train Epoch: 8 [23680/53386 (44%)]	Loss: 0.646665
Train Epoch: 8 [24320/53386 (46%)]	Loss: 0.591793
Train Epoch: 8 [24960/53386 (47%)]	Loss: 0.630070
Train Epoch: 8 [25600/53386 (48%)]	Loss: 0.626710
Train Epoch: 8 [26240/53386 (49%)]	Loss: 0.634587
Train Epoch: 8 [26880/53386 (50%)]	Loss: 0.616049
Train Epoch: 8 [27520/53386 (52%)]	Loss: 0.643238
Train Epoch: 8 [28160/53386 (53%)]	Loss: 0.627343
Train Epoch: 8 [28800/53386 (54%)]	Loss: 0.596830
Train Epoch: 8 [29440/53386 (55%)]	Loss: 0.662720
Train Epoch: 8 [30080/53386 (56%)]	Loss: 0.589229
Train Epoch: 8 [30720/53386 (58%)]	Loss: 0.626634
Train Epoch: 8 [31360/53386 (59%)]	Loss: 0.713153
Train Epoch: 8 [32000/53386 (60%)]	Loss: 0.647925
Train Epoch: 8 [32640/53386 (61%)]	Loss: 0.644704
Train Epoch: 8 [33280/53386 (62%)]	Loss: 0.629125
Train Epoch: 8 [33920/53386 (64%)]	Loss: 0.623257
Train Epoch: 8 [34560/53386 (65%)]	Loss: 0.615964
Train Epoch: 8 [35200/53386 (66%)]	Loss: 0.699419
Train Epoch: 8 [35840/53386 (67%)]	Loss: 0.615260
Train Epoch: 8 [36480/53386 (68%)]	Loss: 0.666831
Train Epoch: 8 [37120/53386 (70%)]	Loss: 0.657332
Train Epoch: 8 [37760/53386 (71%)]	Loss: 0.652390
Train Epoch: 8 [38400/53386 (72%)]	Loss: 0.686278
Train Epoch: 8 [39040/53386 (73%)]	Loss: 0.666223
Train Epoch: 8 [39680/53386 (74%)]	Loss: 0.677464
Train Epoch: 8 [40320/53386 (76%)]	Loss: 0.644790
Train Epoch: 8 [40960/53386 (77%)]	Loss: 0.734281
Train Epoch: 8 [41600/53386 (78%)]	Loss: 0.657574
Train Epoch: 8 [42240/53386 (79%)]	Loss: 0.731434
Train Epoch: 8 [42880/53386 (80%)]	Loss: 0.683962
Train Epoch: 8 [43520/53386 (82%)]	Loss: 0.697139
Train Epoch: 8 [44160/53386 (83%)]	Loss: 0.639505
Train Epoch: 8 [44800/53386 (84%)]	Loss: 0.591618
Train Epoch: 8 [45440/53386 (85%)]	Loss: 0.699194
Train Epoch: 8 [46080/53386 (86%)]	Loss: 0.687285
Train Epoch: 8 [46720/53386 (88%)]	Loss: 0.631473
Train Epoch: 8 [47360/53386 (89%)]	Loss: 0.673232
Train Epoch: 8 [48000/53386 (90%)]	Loss: 0.662964
Train Epoch: 8 [48640/53386 (91%)]	Loss: 0.624946
Train Epoch: 8 [49280/53386 (92%)]	Loss: 0.675674
Train Epoch: 8 [49920/53386 (94%)]	Loss: 0.698268
Train Epoch: 8 [50560/53386 (95%)]	Loss: 0.688870
Train Epoch: 8 [51200/53386 (96%)]	Loss: 0.664891
Train Epoch: 8 [51840/53386 (97%)]	Loss: 0.628825
Train Epoch: 8 [52480/53386 (98%)]	Loss: 0.640062
Train Epoch: 8 [53120/53386 (100%)]	Loss: 0.643415
0.27796278596492113
0.27470415992671815
[[ 638  249  280   81   34  183  218  730]
 [  44  403  123   39   26   31   33  402]
 [ 116  145 1653  162   29   41   72 1122]
 [  34   57  175  115   13   28   30  277]
 [  24   29   51   14   21   13   19  111]
 [  63   64   45   24    6   91   57  136]
 [ 247  131  172   45   12  111  174  431]
 [ 282  482 1184  194   66  120  237 3102]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.2866970023244225
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 9 [640/53386 (1%)]	Loss: 0.594959
Train Epoch: 9 [1280/53386 (2%)]	Loss: 0.430204
Train Epoch: 9 [1920/53386 (4%)]	Loss: 0.539339
Train Epoch: 9 [2560/53386 (5%)]	Loss: 0.509901
Train Epoch: 9 [3200/53386 (6%)]	Loss: 0.461321
Train Epoch: 9 [3840/53386 (7%)]	Loss: 0.498012
Train Epoch: 9 [4480/53386 (8%)]	Loss: 0.480968
Train Epoch: 9 [5120/53386 (10%)]	Loss: 0.517950
Train Epoch: 9 [5760/53386 (11%)]	Loss: 0.482481
Train Epoch: 9 [6400/53386 (12%)]	Loss: 0.463391
Train Epoch: 9 [7040/53386 (13%)]	Loss: 0.567248
Train Epoch: 9 [7680/53386 (14%)]	Loss: 0.518990
Train Epoch: 9 [8320/53386 (16%)]	Loss: 0.498788
Train Epoch: 9 [8960/53386 (17%)]	Loss: 0.505498
Train Epoch: 9 [9600/53386 (18%)]	Loss: 0.542204
Train Epoch: 9 [10240/53386 (19%)]	Loss: 0.479497
Train Epoch: 9 [10880/53386 (20%)]	Loss: 0.452893
Train Epoch: 9 [11520/53386 (22%)]	Loss: 0.589210
Train Epoch: 9 [12160/53386 (23%)]	Loss: 0.554024
Train Epoch: 9 [12800/53386 (24%)]	Loss: 0.518062
Train Epoch: 9 [13440/53386 (25%)]	Loss: 0.483007
Train Epoch: 9 [14080/53386 (26%)]	Loss: 0.487824
Train Epoch: 9 [14720/53386 (28%)]	Loss: 0.450067
Train Epoch: 9 [15360/53386 (29%)]	Loss: 0.568553
Train Epoch: 9 [16000/53386 (30%)]	Loss: 0.587986
Train Epoch: 9 [16640/53386 (31%)]	Loss: 0.564753
Train Epoch: 9 [17280/53386 (32%)]	Loss: 0.484625
Train Epoch: 9 [17920/53386 (34%)]	Loss: 0.515556
Train Epoch: 9 [18560/53386 (35%)]	Loss: 0.503662
Train Epoch: 9 [19200/53386 (36%)]	Loss: 0.492429
Train Epoch: 9 [19840/53386 (37%)]	Loss: 0.552337
Train Epoch: 9 [20480/53386 (38%)]	Loss: 0.544557
Train Epoch: 9 [21120/53386 (40%)]	Loss: 0.515836
Train Epoch: 9 [21760/53386 (41%)]	Loss: 0.485472
Train Epoch: 9 [22400/53386 (42%)]	Loss: 0.581674
Train Epoch: 9 [23040/53386 (43%)]	Loss: 0.575615
Train Epoch: 9 [23680/53386 (44%)]	Loss: 0.550098
Train Epoch: 9 [24320/53386 (46%)]	Loss: 0.488873
Train Epoch: 9 [24960/53386 (47%)]	Loss: 0.526155
Train Epoch: 9 [25600/53386 (48%)]	Loss: 0.536283
Train Epoch: 9 [26240/53386 (49%)]	Loss: 0.538580
Train Epoch: 9 [26880/53386 (50%)]	Loss: 0.505531
Train Epoch: 9 [27520/53386 (52%)]	Loss: 0.460140
Train Epoch: 9 [28160/53386 (53%)]	Loss: 0.510065
Train Epoch: 9 [28800/53386 (54%)]	Loss: 0.511379
Train Epoch: 9 [29440/53386 (55%)]	Loss: 0.470553
Train Epoch: 9 [30080/53386 (56%)]	Loss: 0.524005
Train Epoch: 9 [30720/53386 (58%)]	Loss: 0.498376
Train Epoch: 9 [31360/53386 (59%)]	Loss: 0.637528
Train Epoch: 9 [32000/53386 (60%)]	Loss: 0.560252
Train Epoch: 9 [32640/53386 (61%)]	Loss: 0.538791
Train Epoch: 9 [33280/53386 (62%)]	Loss: 0.498141
Train Epoch: 9 [33920/53386 (64%)]	Loss: 0.526008
Train Epoch: 9 [34560/53386 (65%)]	Loss: 0.548382
Train Epoch: 9 [35200/53386 (66%)]	Loss: 0.576369
Train Epoch: 9 [35840/53386 (67%)]	Loss: 0.517552
Train Epoch: 9 [36480/53386 (68%)]	Loss: 0.520333
Train Epoch: 9 [37120/53386 (70%)]	Loss: 0.535285
Train Epoch: 9 [37760/53386 (71%)]	Loss: 0.516145
Train Epoch: 9 [38400/53386 (72%)]	Loss: 0.499978
Train Epoch: 9 [39040/53386 (73%)]	Loss: 0.548160
Train Epoch: 9 [39680/53386 (74%)]	Loss: 0.549839
Train Epoch: 9 [40320/53386 (76%)]	Loss: 0.461926
Train Epoch: 9 [40960/53386 (77%)]	Loss: 0.514681
Train Epoch: 9 [41600/53386 (78%)]	Loss: 0.487305
Train Epoch: 9 [42240/53386 (79%)]	Loss: 0.548042
Train Epoch: 9 [42880/53386 (80%)]	Loss: 0.535855
Train Epoch: 9 [43520/53386 (82%)]	Loss: 0.554654
Train Epoch: 9 [44160/53386 (83%)]	Loss: 0.546474
Train Epoch: 9 [44800/53386 (84%)]	Loss: 0.553711
Train Epoch: 9 [45440/53386 (85%)]	Loss: 0.463421
Train Epoch: 9 [46080/53386 (86%)]	Loss: 0.580783
Train Epoch: 9 [46720/53386 (88%)]	Loss: 0.612910
Train Epoch: 9 [47360/53386 (89%)]	Loss: 0.526087
Train Epoch: 9 [48000/53386 (90%)]	Loss: 0.564142
Train Epoch: 9 [48640/53386 (91%)]	Loss: 0.564115
Train Epoch: 9 [49280/53386 (92%)]	Loss: 0.531561
Train Epoch: 9 [49920/53386 (94%)]	Loss: 0.537145
Train Epoch: 9 [50560/53386 (95%)]	Loss: 0.561974
Train Epoch: 9 [51200/53386 (96%)]	Loss: 0.511424
Train Epoch: 9 [51840/53386 (97%)]	Loss: 0.508252
Train Epoch: 9 [52480/53386 (98%)]	Loss: 0.503592
Train Epoch: 9 [53120/53386 (100%)]	Loss: 0.510775
0.26221465710375724
0.2659115575370025
[[ 546  164  268   89   28  163  331  824]
 [  42  334  107   29   21   21   47  500]
 [  90  105 1431  155   20   34  105 1400]
 [  33   39  154  115    5   22   36  325]
 [  29   17   43   13   14   10   21  135]
 [  62   36   47   22    7   81   70  161]
 [ 197   93  165   61   14  108  210  475]
 [ 225  310 1059  189   49   94  302 3439]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.2866970023244225
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 10 [640/53386 (1%)]	Loss: 0.411447
Train Epoch: 10 [1280/53386 (2%)]	Loss: 0.320563
Train Epoch: 10 [1920/53386 (4%)]	Loss: 0.362276
Train Epoch: 10 [2560/53386 (5%)]	Loss: 0.438233
Train Epoch: 10 [3200/53386 (6%)]	Loss: 0.455810
Train Epoch: 10 [3840/53386 (7%)]	Loss: 0.377009
Train Epoch: 10 [4480/53386 (8%)]	Loss: 0.446248
Train Epoch: 10 [5120/53386 (10%)]	Loss: 0.349272
Train Epoch: 10 [5760/53386 (11%)]	Loss: 0.376652
Train Epoch: 10 [6400/53386 (12%)]	Loss: 0.383229
Train Epoch: 10 [7040/53386 (13%)]	Loss: 0.469942
Train Epoch: 10 [7680/53386 (14%)]	Loss: 0.408750
Train Epoch: 10 [8320/53386 (16%)]	Loss: 0.438802
Train Epoch: 10 [8960/53386 (17%)]	Loss: 0.378199
Train Epoch: 10 [9600/53386 (18%)]	Loss: 0.421031
Train Epoch: 10 [10240/53386 (19%)]	Loss: 0.349147
Train Epoch: 10 [10880/53386 (20%)]	Loss: 0.433111
Train Epoch: 10 [11520/53386 (22%)]	Loss: 0.402616
Train Epoch: 10 [12160/53386 (23%)]	Loss: 0.333509
Train Epoch: 10 [12800/53386 (24%)]	Loss: 0.374183
Train Epoch: 10 [13440/53386 (25%)]	Loss: 0.440802
Train Epoch: 10 [14080/53386 (26%)]	Loss: 0.436077
Train Epoch: 10 [14720/53386 (28%)]	Loss: 0.406260
Train Epoch: 10 [15360/53386 (29%)]	Loss: 0.446936
Train Epoch: 10 [16000/53386 (30%)]	Loss: 0.424962
Train Epoch: 10 [16640/53386 (31%)]	Loss: 0.425258
Train Epoch: 10 [17280/53386 (32%)]	Loss: 0.436248
Train Epoch: 10 [17920/53386 (34%)]	Loss: 0.350728
Train Epoch: 10 [18560/53386 (35%)]	Loss: 0.460517
Train Epoch: 10 [19200/53386 (36%)]	Loss: 0.413852
Train Epoch: 10 [19840/53386 (37%)]	Loss: 0.355558
Train Epoch: 10 [20480/53386 (38%)]	Loss: 0.392084
Train Epoch: 10 [21120/53386 (40%)]	Loss: 0.391227
Train Epoch: 10 [21760/53386 (41%)]	Loss: 0.386530
Train Epoch: 10 [22400/53386 (42%)]	Loss: 0.463542
Train Epoch: 10 [23040/53386 (43%)]	Loss: 0.394535
Train Epoch: 10 [23680/53386 (44%)]	Loss: 0.432659
Train Epoch: 10 [24320/53386 (46%)]	Loss: 0.482697
Train Epoch: 10 [24960/53386 (47%)]	Loss: 0.406913
Train Epoch: 10 [25600/53386 (48%)]	Loss: 0.465246
Train Epoch: 10 [26240/53386 (49%)]	Loss: 0.391464
Train Epoch: 10 [26880/53386 (50%)]	Loss: 0.460226
Train Epoch: 10 [27520/53386 (52%)]	Loss: 0.482959
Train Epoch: 10 [28160/53386 (53%)]	Loss: 0.374391
Train Epoch: 10 [28800/53386 (54%)]	Loss: 0.488682
Train Epoch: 10 [29440/53386 (55%)]	Loss: 0.404331
Train Epoch: 10 [30080/53386 (56%)]	Loss: 0.452553
Train Epoch: 10 [30720/53386 (58%)]	Loss: 0.451950
Train Epoch: 10 [31360/53386 (59%)]	Loss: 0.385204
Train Epoch: 10 [32000/53386 (60%)]	Loss: 0.385493
Train Epoch: 10 [32640/53386 (61%)]	Loss: 0.422390
Train Epoch: 10 [33280/53386 (62%)]	Loss: 0.442554
Train Epoch: 10 [33920/53386 (64%)]	Loss: 0.437094
Train Epoch: 10 [34560/53386 (65%)]	Loss: 0.386399
Train Epoch: 10 [35200/53386 (66%)]	Loss: 0.391286
Train Epoch: 10 [35840/53386 (67%)]	Loss: 0.435518
Train Epoch: 10 [36480/53386 (68%)]	Loss: 0.421444
Train Epoch: 10 [37120/53386 (70%)]	Loss: 0.444018
Train Epoch: 10 [37760/53386 (71%)]	Loss: 0.470940
Train Epoch: 10 [38400/53386 (72%)]	Loss: 0.429235
Train Epoch: 10 [39040/53386 (73%)]	Loss: 0.427213
Train Epoch: 10 [39680/53386 (74%)]	Loss: 0.428823
Train Epoch: 10 [40320/53386 (76%)]	Loss: 0.515738
Train Epoch: 10 [40960/53386 (77%)]	Loss: 0.416781
Train Epoch: 10 [41600/53386 (78%)]	Loss: 0.489415
Train Epoch: 10 [42240/53386 (79%)]	Loss: 0.418192
Train Epoch: 10 [42880/53386 (80%)]	Loss: 0.469590
Train Epoch: 10 [43520/53386 (82%)]	Loss: 0.431546
Train Epoch: 10 [44160/53386 (83%)]	Loss: 0.399334
Train Epoch: 10 [44800/53386 (84%)]	Loss: 0.349774
Train Epoch: 10 [45440/53386 (85%)]	Loss: 0.398600
Train Epoch: 10 [46080/53386 (86%)]	Loss: 0.404690
Train Epoch: 10 [46720/53386 (88%)]	Loss: 0.408799
Train Epoch: 10 [47360/53386 (89%)]	Loss: 0.426240
Train Epoch: 10 [48000/53386 (90%)]	Loss: 0.406735
Train Epoch: 10 [48640/53386 (91%)]	Loss: 0.479815
Train Epoch: 10 [49280/53386 (92%)]	Loss: 0.433470
Train Epoch: 10 [49920/53386 (94%)]	Loss: 0.443937
Train Epoch: 10 [50560/53386 (95%)]	Loss: 0.401056
Train Epoch: 10 [51200/53386 (96%)]	Loss: 0.476325
Train Epoch: 10 [51840/53386 (97%)]	Loss: 0.452365
Train Epoch: 10 [52480/53386 (98%)]	Loss: 0.439505
Train Epoch: 10 [53120/53386 (100%)]	Loss: 0.443992
0.2641012020711566
0.2672857842636762
[[ 556  134  298   74   42  213  348  748]
 [  47  276  122   24   33   36   53  510]
 [  92   84 1586  105   21   50  124 1278]
 [  29   28  182   96    9   30   50  305]
 [  25   17   44   10   20   14   25  127]
 [  62   21   45   22   14   93   78  151]
 [ 197   74  182   50   15  127  241  437]
 [ 249  254 1201  147   55  130  340 3291]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.2866970023244225
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 11 [640/53386 (1%)]	Loss: 0.351306
Train Epoch: 11 [1280/53386 (2%)]	Loss: 0.351984
Train Epoch: 11 [1920/53386 (4%)]	Loss: 0.324931
Train Epoch: 11 [2560/53386 (5%)]	Loss: 0.326933
Train Epoch: 11 [3200/53386 (6%)]	Loss: 0.295134
Train Epoch: 11 [3840/53386 (7%)]	Loss: 0.311594
Train Epoch: 11 [4480/53386 (8%)]	Loss: 0.408254
Train Epoch: 11 [5120/53386 (10%)]	Loss: 0.330094
Train Epoch: 11 [5760/53386 (11%)]	Loss: 0.320396
Train Epoch: 11 [6400/53386 (12%)]	Loss: 0.347506
Train Epoch: 11 [7040/53386 (13%)]	Loss: 0.397835
Train Epoch: 11 [7680/53386 (14%)]	Loss: 0.364326
Train Epoch: 11 [8320/53386 (16%)]	Loss: 0.334259
Train Epoch: 11 [8960/53386 (17%)]	Loss: 0.309365
Train Epoch: 11 [9600/53386 (18%)]	Loss: 0.395664
Train Epoch: 11 [10240/53386 (19%)]	Loss: 0.360726
Train Epoch: 11 [10880/53386 (20%)]	Loss: 0.299836
Train Epoch: 11 [11520/53386 (22%)]	Loss: 0.321461
Train Epoch: 11 [12160/53386 (23%)]	Loss: 0.345033
Train Epoch: 11 [12800/53386 (24%)]	Loss: 0.339051
Train Epoch: 11 [13440/53386 (25%)]	Loss: 0.359608
Train Epoch: 11 [14080/53386 (26%)]	Loss: 0.358145
Train Epoch: 11 [14720/53386 (28%)]	Loss: 0.315356
Train Epoch: 11 [15360/53386 (29%)]	Loss: 0.331676
Train Epoch: 11 [16000/53386 (30%)]	Loss: 0.298854
Train Epoch: 11 [16640/53386 (31%)]	Loss: 0.314038
Train Epoch: 11 [17280/53386 (32%)]	Loss: 0.354857
Train Epoch: 11 [17920/53386 (34%)]	Loss: 0.320907
Train Epoch: 11 [18560/53386 (35%)]	Loss: 0.339816
Train Epoch: 11 [19200/53386 (36%)]	Loss: 0.295134
Train Epoch: 11 [19840/53386 (37%)]	Loss: 0.305855
Train Epoch: 11 [20480/53386 (38%)]	Loss: 0.338457
Train Epoch: 11 [21120/53386 (40%)]	Loss: 0.362374
Train Epoch: 11 [21760/53386 (41%)]	Loss: 0.296225
Train Epoch: 11 [22400/53386 (42%)]	Loss: 0.324979
Train Epoch: 11 [23040/53386 (43%)]	Loss: 0.324303
Train Epoch: 11 [23680/53386 (44%)]	Loss: 0.303381
Train Epoch: 11 [24320/53386 (46%)]	Loss: 0.300006
Train Epoch: 11 [24960/53386 (47%)]	Loss: 0.311725
Train Epoch: 11 [25600/53386 (48%)]	Loss: 0.321682
Train Epoch: 11 [26240/53386 (49%)]	Loss: 0.333939
Train Epoch: 11 [26880/53386 (50%)]	Loss: 0.336044
Train Epoch: 11 [27520/53386 (52%)]	Loss: 0.357778
Train Epoch: 11 [28160/53386 (53%)]	Loss: 0.343613
Train Epoch: 11 [28800/53386 (54%)]	Loss: 0.382079
Train Epoch: 11 [29440/53386 (55%)]	Loss: 0.340000
Train Epoch: 11 [30080/53386 (56%)]	Loss: 0.379178
Train Epoch: 11 [30720/53386 (58%)]	Loss: 0.373544
Train Epoch: 11 [31360/53386 (59%)]	Loss: 0.317891
Train Epoch: 11 [32000/53386 (60%)]	Loss: 0.380701
Train Epoch: 11 [32640/53386 (61%)]	Loss: 0.308068
Train Epoch: 11 [33280/53386 (62%)]	Loss: 0.357393
Train Epoch: 11 [33920/53386 (64%)]	Loss: 0.306422
Train Epoch: 11 [34560/53386 (65%)]	Loss: 0.326580
Train Epoch: 11 [35200/53386 (66%)]	Loss: 0.369691
Train Epoch: 11 [35840/53386 (67%)]	Loss: 0.376830
Train Epoch: 11 [36480/53386 (68%)]	Loss: 0.302456
Train Epoch: 11 [37120/53386 (70%)]	Loss: 0.306971
Train Epoch: 11 [37760/53386 (71%)]	Loss: 0.373818
Train Epoch: 11 [38400/53386 (72%)]	Loss: 0.343801
Train Epoch: 11 [39040/53386 (73%)]	Loss: 0.487554
Train Epoch: 11 [39680/53386 (74%)]	Loss: 0.275556
Train Epoch: 11 [40320/53386 (76%)]	Loss: 0.340898
Train Epoch: 11 [40960/53386 (77%)]	Loss: 0.335267
Train Epoch: 11 [41600/53386 (78%)]	Loss: 0.265452
Train Epoch: 11 [42240/53386 (79%)]	Loss: 0.444363
Train Epoch: 11 [42880/53386 (80%)]	Loss: 0.333175
Train Epoch: 11 [43520/53386 (82%)]	Loss: 0.353771
Train Epoch: 11 [44160/53386 (83%)]	Loss: 0.398823
Train Epoch: 11 [44800/53386 (84%)]	Loss: 0.349794
Train Epoch: 11 [45440/53386 (85%)]	Loss: 0.338618
Train Epoch: 11 [46080/53386 (86%)]	Loss: 0.379923
Train Epoch: 11 [46720/53386 (88%)]	Loss: 0.372153
Train Epoch: 11 [47360/53386 (89%)]	Loss: 0.357992
Train Epoch: 11 [48000/53386 (90%)]	Loss: 0.383162
Train Epoch: 11 [48640/53386 (91%)]	Loss: 0.362182
Train Epoch: 11 [49280/53386 (92%)]	Loss: 0.342863
Train Epoch: 11 [49920/53386 (94%)]	Loss: 0.348921
Train Epoch: 11 [50560/53386 (95%)]	Loss: 0.322318
Train Epoch: 11 [51200/53386 (96%)]	Loss: 0.322443
Train Epoch: 11 [51840/53386 (97%)]	Loss: 0.334910
Train Epoch: 11 [52480/53386 (98%)]	Loss: 0.399404
Train Epoch: 11 [53120/53386 (100%)]	Loss: 0.311528
0.25880808169799274
0.26399976407892967
[[ 600  154  285   66   20  154  268  866]
 [  50  309  132   26   18   23   40  503]
 [ 100   81 1508  122   11   28  100 1390]
 [  32   37  183   89    6   23   35  324]
 [  30   15   47   10   11    8   20  141]
 [  63   33   48   18    5   90   63  166]
 [ 237   89  189   43    4  107  172  482]
 [ 287  290 1106  141   38   94  235 3476]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.2866970023244225
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 12 [640/53386 (1%)]	Loss: 0.343623
Train Epoch: 12 [1280/53386 (2%)]	Loss: 0.261986
Train Epoch: 12 [1920/53386 (4%)]	Loss: 0.201234
Train Epoch: 12 [2560/53386 (5%)]	Loss: 0.243997
Train Epoch: 12 [3200/53386 (6%)]	Loss: 0.287127
Train Epoch: 12 [3840/53386 (7%)]	Loss: 0.258076
Train Epoch: 12 [4480/53386 (8%)]	Loss: 0.234677
Train Epoch: 12 [5120/53386 (10%)]	Loss: 0.276671
Train Epoch: 12 [5760/53386 (11%)]	Loss: 0.244044
Train Epoch: 12 [6400/53386 (12%)]	Loss: 0.276147
Train Epoch: 12 [7040/53386 (13%)]	Loss: 0.241375
Train Epoch: 12 [7680/53386 (14%)]	Loss: 0.256091
Train Epoch: 12 [8320/53386 (16%)]	Loss: 0.229319
Train Epoch: 12 [8960/53386 (17%)]	Loss: 0.250666
Train Epoch: 12 [9600/53386 (18%)]	Loss: 0.210738
Train Epoch: 12 [10240/53386 (19%)]	Loss: 0.262870
Train Epoch: 12 [10880/53386 (20%)]	Loss: 0.217638
Train Epoch: 12 [11520/53386 (22%)]	Loss: 0.277717
Train Epoch: 12 [12160/53386 (23%)]	Loss: 0.231708
Train Epoch: 12 [12800/53386 (24%)]	Loss: 0.262809
Train Epoch: 12 [13440/53386 (25%)]	Loss: 0.306058
Train Epoch: 12 [14080/53386 (26%)]	Loss: 0.277293
Train Epoch: 12 [14720/53386 (28%)]	Loss: 0.260849
Train Epoch: 12 [15360/53386 (29%)]	Loss: 0.329478
Train Epoch: 12 [16000/53386 (30%)]	Loss: 0.283735
Train Epoch: 12 [16640/53386 (31%)]	Loss: 0.265721
Train Epoch: 12 [17280/53386 (32%)]	Loss: 0.260997
Train Epoch: 12 [17920/53386 (34%)]	Loss: 0.248362
Train Epoch: 12 [18560/53386 (35%)]	Loss: 0.232306
Train Epoch: 12 [19200/53386 (36%)]	Loss: 0.321979
Train Epoch: 12 [19840/53386 (37%)]	Loss: 0.327915
Train Epoch: 12 [20480/53386 (38%)]	Loss: 0.304397
Train Epoch: 12 [21120/53386 (40%)]	Loss: 0.320465
Train Epoch: 12 [21760/53386 (41%)]	Loss: 0.306401
Train Epoch: 12 [22400/53386 (42%)]	Loss: 0.297871
Train Epoch: 12 [23040/53386 (43%)]	Loss: 0.327540
Train Epoch: 12 [23680/53386 (44%)]	Loss: 0.332564
Train Epoch: 12 [24320/53386 (46%)]	Loss: 0.243881
Train Epoch: 12 [24960/53386 (47%)]	Loss: 0.263402
Train Epoch: 12 [25600/53386 (48%)]	Loss: 0.279590
Train Epoch: 12 [26240/53386 (49%)]	Loss: 0.289116
Train Epoch: 12 [26880/53386 (50%)]	Loss: 0.345397
Train Epoch: 12 [27520/53386 (52%)]	Loss: 0.247560
Train Epoch: 12 [28160/53386 (53%)]	Loss: 0.245797
Train Epoch: 12 [28800/53386 (54%)]	Loss: 0.256898
Train Epoch: 12 [29440/53386 (55%)]	Loss: 0.249992
Train Epoch: 12 [30080/53386 (56%)]	Loss: 0.303148
Train Epoch: 12 [30720/53386 (58%)]	Loss: 0.290535
Train Epoch: 12 [31360/53386 (59%)]	Loss: 0.375421
Train Epoch: 12 [32000/53386 (60%)]	Loss: 0.290516
Train Epoch: 12 [32640/53386 (61%)]	Loss: 0.300115
Train Epoch: 12 [33280/53386 (62%)]	Loss: 0.230494
Train Epoch: 12 [33920/53386 (64%)]	Loss: 0.277696
Train Epoch: 12 [34560/53386 (65%)]	Loss: 0.254900
Train Epoch: 12 [35200/53386 (66%)]	Loss: 0.283918
Train Epoch: 12 [35840/53386 (67%)]	Loss: 0.288779
Train Epoch: 12 [36480/53386 (68%)]	Loss: 0.285079
Train Epoch: 12 [37120/53386 (70%)]	Loss: 0.299586
Train Epoch: 12 [37760/53386 (71%)]	Loss: 0.208692
Train Epoch: 12 [38400/53386 (72%)]	Loss: 0.292399
Train Epoch: 12 [39040/53386 (73%)]	Loss: 0.281283
Train Epoch: 12 [39680/53386 (74%)]	Loss: 0.282986
Train Epoch: 12 [40320/53386 (76%)]	Loss: 0.293522
Train Epoch: 12 [40960/53386 (77%)]	Loss: 0.269621
Train Epoch: 12 [41600/53386 (78%)]	Loss: 0.360291
Train Epoch: 12 [42240/53386 (79%)]	Loss: 0.288543
Train Epoch: 12 [42880/53386 (80%)]	Loss: 0.293209
Train Epoch: 12 [43520/53386 (82%)]	Loss: 0.289116
Train Epoch: 12 [44160/53386 (83%)]	Loss: 0.292337
Train Epoch: 12 [44800/53386 (84%)]	Loss: 0.263512
Train Epoch: 12 [45440/53386 (85%)]	Loss: 0.276608
Train Epoch: 12 [46080/53386 (86%)]	Loss: 0.324678
Train Epoch: 12 [46720/53386 (88%)]	Loss: 0.280725
Train Epoch: 12 [47360/53386 (89%)]	Loss: 0.343389
Train Epoch: 12 [48000/53386 (90%)]	Loss: 0.288581
Train Epoch: 12 [48640/53386 (91%)]	Loss: 0.246690
Train Epoch: 12 [49280/53386 (92%)]	Loss: 0.288008
Train Epoch: 12 [49920/53386 (94%)]	Loss: 0.284091
Train Epoch: 12 [50560/53386 (95%)]	Loss: 0.286704
Train Epoch: 12 [51200/53386 (96%)]	Loss: 0.295791
Train Epoch: 12 [51840/53386 (97%)]	Loss: 0.301594
Train Epoch: 12 [52480/53386 (98%)]	Loss: 0.322652
Train Epoch: 12 [53120/53386 (100%)]	Loss: 0.295304
0.26182161193828224
0.26305380104921494
[[ 657  137  311  167   42  154  192  753]
 [  73  306  127   52   31   30   31  451]
 [ 127   75 1501  252   30   30   75 1250]
 [  42   34  154  153    9   17   21  299]
 [  36   13   48   20   17   10   16  122]
 [  77   26   49   37   10   73   55  159]
 [ 268   79  181  106   15   87  141  446]
 [ 312  254 1182  293   99   93  215 3219]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.2866970023244225
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 13 [640/53386 (1%)]	Loss: 0.272162
Train Epoch: 13 [1280/53386 (2%)]	Loss: 0.215111
Train Epoch: 13 [1920/53386 (4%)]	Loss: 0.179864
Train Epoch: 13 [2560/53386 (5%)]	Loss: 0.220973
Train Epoch: 13 [3200/53386 (6%)]	Loss: 0.182582
Train Epoch: 13 [3840/53386 (7%)]	Loss: 0.181274
Train Epoch: 13 [4480/53386 (8%)]	Loss: 0.197822
Train Epoch: 13 [5120/53386 (10%)]	Loss: 0.232422
Train Epoch: 13 [5760/53386 (11%)]	Loss: 0.215725
Train Epoch: 13 [6400/53386 (12%)]	Loss: 0.210776
Train Epoch: 13 [7040/53386 (13%)]	Loss: 0.207831
Train Epoch: 13 [7680/53386 (14%)]	Loss: 0.224134
Train Epoch: 13 [8320/53386 (16%)]	Loss: 0.250910
Train Epoch: 13 [8960/53386 (17%)]	Loss: 0.203954
Train Epoch: 13 [9600/53386 (18%)]	Loss: 0.222203
Train Epoch: 13 [10240/53386 (19%)]	Loss: 0.198051
Train Epoch: 13 [10880/53386 (20%)]	Loss: 0.199499
Train Epoch: 13 [11520/53386 (22%)]	Loss: 0.218699
Train Epoch: 13 [12160/53386 (23%)]	Loss: 0.228142
Train Epoch: 13 [12800/53386 (24%)]	Loss: 0.300234
Train Epoch: 13 [13440/53386 (25%)]	Loss: 0.215684
Train Epoch: 13 [14080/53386 (26%)]	Loss: 0.259563
Train Epoch: 13 [14720/53386 (28%)]	Loss: 0.233810
Train Epoch: 13 [15360/53386 (29%)]	Loss: 0.228628
Train Epoch: 13 [16000/53386 (30%)]	Loss: 0.263559
Train Epoch: 13 [16640/53386 (31%)]	Loss: 0.216743
Train Epoch: 13 [17280/53386 (32%)]	Loss: 0.228001
Train Epoch: 13 [17920/53386 (34%)]	Loss: 0.283459
Train Epoch: 13 [18560/53386 (35%)]	Loss: 0.239377
Train Epoch: 13 [19200/53386 (36%)]	Loss: 0.202291
Train Epoch: 13 [19840/53386 (37%)]	Loss: 0.196727
Train Epoch: 13 [20480/53386 (38%)]	Loss: 0.231770
Train Epoch: 13 [21120/53386 (40%)]	Loss: 0.223727
Train Epoch: 13 [21760/53386 (41%)]	Loss: 0.235358
Train Epoch: 13 [22400/53386 (42%)]	Loss: 0.232732
Train Epoch: 13 [23040/53386 (43%)]	Loss: 0.274115
Train Epoch: 13 [23680/53386 (44%)]	Loss: 0.174864
Train Epoch: 13 [24320/53386 (46%)]	Loss: 0.172022
Train Epoch: 13 [24960/53386 (47%)]	Loss: 0.237996
Train Epoch: 13 [25600/53386 (48%)]	Loss: 0.195161
Train Epoch: 13 [26240/53386 (49%)]	Loss: 0.237985
Train Epoch: 13 [26880/53386 (50%)]	Loss: 0.286272
Train Epoch: 13 [27520/53386 (52%)]	Loss: 0.253334
Train Epoch: 13 [28160/53386 (53%)]	Loss: 0.238528
Train Epoch: 13 [28800/53386 (54%)]	Loss: 0.242746
Train Epoch: 13 [29440/53386 (55%)]	Loss: 0.275741
Train Epoch: 13 [30080/53386 (56%)]	Loss: 0.224197
Train Epoch: 13 [30720/53386 (58%)]	Loss: 0.245682
Train Epoch: 13 [31360/53386 (59%)]	Loss: 0.248556
Train Epoch: 13 [32000/53386 (60%)]	Loss: 0.219146
Train Epoch: 13 [32640/53386 (61%)]	Loss: 0.274229
Train Epoch: 13 [33280/53386 (62%)]	Loss: 0.200014
Train Epoch: 13 [33920/53386 (64%)]	Loss: 0.246604
Train Epoch: 13 [34560/53386 (65%)]	Loss: 0.242842
Train Epoch: 13 [35200/53386 (66%)]	Loss: 0.279849
Train Epoch: 13 [35840/53386 (67%)]	Loss: 0.252905
Train Epoch: 13 [36480/53386 (68%)]	Loss: 0.222359
Train Epoch: 13 [37120/53386 (70%)]	Loss: 0.208818
Train Epoch: 13 [37760/53386 (71%)]	Loss: 0.192704
Train Epoch: 13 [38400/53386 (72%)]	Loss: 0.292916
Train Epoch: 13 [39040/53386 (73%)]	Loss: 0.202960
Train Epoch: 13 [39680/53386 (74%)]	Loss: 0.211691
Train Epoch: 13 [40320/53386 (76%)]	Loss: 0.209661
Train Epoch: 13 [40960/53386 (77%)]	Loss: 0.219371
Train Epoch: 13 [41600/53386 (78%)]	Loss: 0.252705
Train Epoch: 13 [42240/53386 (79%)]	Loss: 0.186796
Train Epoch: 13 [42880/53386 (80%)]	Loss: 0.252385
Train Epoch: 13 [43520/53386 (82%)]	Loss: 0.235181
Train Epoch: 13 [44160/53386 (83%)]	Loss: 0.223919
Train Epoch: 13 [44800/53386 (84%)]	Loss: 0.249995
Train Epoch: 13 [45440/53386 (85%)]	Loss: 0.221433
Train Epoch: 13 [46080/53386 (86%)]	Loss: 0.254408
Train Epoch: 13 [46720/53386 (88%)]	Loss: 0.237122
Train Epoch: 13 [47360/53386 (89%)]	Loss: 0.235428
Train Epoch: 13 [48000/53386 (90%)]	Loss: 0.233131
Train Epoch: 13 [48640/53386 (91%)]	Loss: 0.243013
Train Epoch: 13 [49280/53386 (92%)]	Loss: 0.221631
Train Epoch: 13 [49920/53386 (94%)]	Loss: 0.244075
Train Epoch: 13 [50560/53386 (95%)]	Loss: 0.267983
Train Epoch: 13 [51200/53386 (96%)]	Loss: 0.234960
Train Epoch: 13 [51840/53386 (97%)]	Loss: 0.219313
Train Epoch: 13 [52480/53386 (98%)]	Loss: 0.275493
Train Epoch: 13 [53120/53386 (100%)]	Loss: 0.223131
0.2571459289019387
0.257016801895517
[[ 617  223  293  110   37  145  223  765]
 [  51  350  106   48   26   30   31  459]
 [  99  119 1497  176   34   46   93 1276]
 [  28   45  179  116   12   18   26  305]
 [  37   26   33   14   14    9   17  132]
 [  67   44   47   35   11   72   47  163]
 [ 245  105  170   80   19   99  144  461]
 [ 271  376 1148  231   82  101  230 3228]]
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  FutureWarning,
Best Result Until Now:
0.2866970023244225
/mnt/data1/liyongwei/conda/envs/sxh/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Train Epoch: 14 [640/53386 (1%)]	Loss: 0.215134
Train Epoch: 14 [1280/53386 (2%)]	Loss: 0.201333
Train Epoch: 14 [1920/53386 (4%)]	Loss: 0.158761
Train Epoch: 14 [2560/53386 (5%)]	Loss: 0.158265
Train Epoch: 14 [3200/53386 (6%)]	Loss: 0.128982
Train Epoch: 14 [3840/53386 (7%)]	Loss: 0.172417
Train Epoch: 14 [4480/53386 (8%)]	Loss: 0.151861
Train Epoch: 14 [5120/53386 (10%)]	Loss: 0.195896
Train Epoch: 14 [5760/53386 (11%)]	Loss: 0.188301
Train Epoch: 14 [6400/53386 (12%)]	Loss: 0.169538
Train Epoch: 14 [7040/53386 (13%)]	Loss: 0.125472
Train Epoch: 14 [7680/53386 (14%)]	Loss: 0.196388
Train Epoch: 14 [8320/53386 (16%)]	Loss: 0.198937
Train Epoch: 14 [8960/53386 (17%)]	Loss: 0.144935
Train Epoch: 14 [9600/53386 (18%)]	Loss: 0.148810
Train Epoch: 14 [10240/53386 (19%)]	Loss: 0.201764
Train Epoch: 14 [10880/53386 (20%)]	Loss: 0.182626
Train Epoch: 14 [11520/53386 (22%)]	Loss: 0.211197
